{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from recbole.data.dataloader import *\n",
    "import torch\n",
    "from pandas import DataFrame\n",
    "from torch import Tensor\n",
    "from recbole.config import Config\n",
    "from recbole.data.dataset import Dataset\n",
    "from recbole.utils import (\n",
    "    FeatureType,\n",
    "    set_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELTYPE_CUTOFF = 7\n",
    "\n",
    "class TimeCutoffDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        self.timestamp_max, self.timestamp_min = 0., 0.\n",
    "        self.cutoff, self.cutoff_conv = 0., 0.\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "    def _normalize(self):\n",
    "        # Extract max-min of field self.time_field\n",
    "        # feat_timestamp = self.field2feats(self.time_field)[0]\n",
    "        # assert feat_timestamp and self.time_field in feat_timestamp, f\"Feat not exist field '{self.time_field}'\"\n",
    "\n",
    "        # self.timestamp_max = np.max(feat_timestamp[self.time_field])\n",
    "        # self.timestamp_min = np.min(feat_timestamp[self.time_field])\n",
    "\n",
    "        self.timestamp_max = np.max(self.inter_feat[self.time_field])\n",
    "        self.timestamp_min = np.min(self.inter_feat[self.time_field])\n",
    "\n",
    "        return super()._normalize()\n",
    "\n",
    "    def _fill_nan(self):\n",
    "        \"\"\"Missing value imputation.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.TOKEN`, missing value will be filled by\n",
    "        ``[PAD]``, which indexed as 0.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.FLOAT`, missing value will be filled by\n",
    "        the average of original data.\n",
    "\n",
    "        Note:\n",
    "            This is similar to the recbole's original implementation. The difference is the change in inplace operation to suit the pandas 3.0\n",
    "        \"\"\"\n",
    "        self.logger.debug(set_color(\"Filling nan\", \"green\"))\n",
    "\n",
    "        for feat_name in self.feat_name_list:\n",
    "            feat = getattr(self, feat_name)\n",
    "            for field in feat:\n",
    "                ftype = self.field2type[field]\n",
    "                if ftype == FeatureType.TOKEN:\n",
    "                    feat[field] = feat[field].fillna(value=0)\n",
    "                elif ftype == FeatureType.FLOAT:\n",
    "                    feat[field] = feat[field].fillna(value=feat[field].mean())\n",
    "                else:\n",
    "                    dtype = np.int64 if ftype == FeatureType.TOKEN_SEQ else np.float64\n",
    "                    feat[field] = feat[field].apply(\n",
    "                        lambda x: (\n",
    "                            np.array([], dtype=dtype) if isinstance(x, float) else x\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    def build(self):\n",
    "        self._change_feat_format()\n",
    "\n",
    "        if self.benchmark_filename_list is not None:\n",
    "            super().build()\n",
    "\n",
    "        # ordering\n",
    "        ordering_args = self.config[\"eval_args\"][\"order\"]\n",
    "        if ordering_args == \"TO\":\n",
    "            self.sort(by=self.time_field)\n",
    "        else:\n",
    "            raise AssertionError(\"The ordering_method must be 'TO.\")\n",
    "\n",
    "        # splitting & grouping\n",
    "        split_args = self.config[\"eval_args\"][\"split\"]\n",
    "        if split_args is None:\n",
    "            raise ValueError(\"The split_args in eval_args should not be None.\")\n",
    "        if not isinstance(split_args, dict):\n",
    "            raise ValueError(f\"The split_args [{split_args}] should be a dict.\")\n",
    "\n",
    "        split_mode = list(split_args.keys())[0]\n",
    "        assert len(split_args.keys()) == 1\n",
    "        if split_mode != \"CO\":\n",
    "            raise NotImplementedError(\"The split_mode must be 'CO'.\")\n",
    "        elif split_mode == \"CO\":\n",
    "            cutoff = split_args[\"CO\"]\n",
    "            # NOTE: HoangLe [Jun-05]: cutoff may come with different types: string, int\n",
    "\n",
    "            group_by = self.config[\"eval_args\"][\"group_by\"]\n",
    "            datasets = self.split_by_cuttoff(cutoff=cutoff, group_by=group_by)\n",
    "    \n",
    "        return datasets\n",
    "\n",
    "    def split_by_cuttoff(self, cutoff: str|int, group_by: str) -> list[Dataset]:\n",
    "        \"\"\"Split the interations by cutoff date\n",
    "\n",
    "        Args:\n",
    "            cutoff (str | int): cutoff date in Unix timestamp format\n",
    "            group_by (str): field to group by, usually the user_id\n",
    "\n",
    "        Returns:\n",
    "            list[Dataset]: list of training/validation/testing dataset, whose interaction features has been split.\n",
    "\n",
    "        Notes:\n",
    "            cutoff may be different types: string of Unix timestamp (e.g. '1717923174'), integer of Unix timestamp (e.g. 1717923174)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.debug(f\"split by cutoff date = '{cutoff}', group_by=[{group_by}]\")\n",
    "\n",
    "        assert self.inter_feat\n",
    "\n",
    "        # Convert cutoff to suitable format and apply 0-1 normalization with max/min timestamp\n",
    "        cutoff_conv = float(cutoff)\n",
    "        self.cutoff = cutoff_conv\n",
    "\n",
    "\n",
    "        def norm_timestamp(timestamp: float):\n",
    "            mx, mn = self.timestamp_max, self.timestamp_min\n",
    "            if mx == mn:\n",
    "                self.logger.warning(\n",
    "                    f\"All the same value in [{field}] from [{feat}_feat].\"\n",
    "                )\n",
    "                arr = 1.0\n",
    "            else:\n",
    "                arr = (timestamp - mn) / (mx - mn)\n",
    "            return arr\n",
    "\n",
    "        cutoff_conv = norm_timestamp(cutoff_conv)\n",
    "        self.cutoff_conv = cutoff_conv\n",
    "            \n",
    "        match self.inter_feat[group_by]:\n",
    "            case DataFrame():\n",
    "                inter_feat_grouby_numpy = self.inter_feat[group_by].to_numpy()\n",
    "            case Tensor():\n",
    "                inter_feat_grouby_numpy = self.inter_feat[group_by].numpy()\n",
    "            case _:\n",
    "                raise TypeError(f\"self.inter_feat[group_by] has type: {type(self.inter_feat[group_by])} - which must be either DataFrame() or Tensor()\")\n",
    "        \n",
    "\n",
    "        grouped_inter_feat_index = self._grouped_index(inter_feat_grouby_numpy)\n",
    "\n",
    "        indices_train, indices_val, indices_test = [], [], []\n",
    "        for grouped_index in grouped_inter_feat_index:\n",
    "            df_each_user = self.inter_feat[grouped_index]\n",
    "            \n",
    "            n_trainval = torch.sum((df_each_user[self.time_field] <= self.cutoff_conv).to(dtype=torch.int32))\n",
    "            n_test = len(df_each_user) - n_trainval\n",
    "\n",
    "            if n_trainval == 0:\n",
    "                continue\n",
    "\n",
    "            if n_trainval >= 1:\n",
    "                indices_train.extend(grouped_index[:n_trainval - 1])\n",
    "            if n_trainval >= 2:\n",
    "                indices_val.append(grouped_index[n_trainval - 1])\n",
    "            if n_test > 0:\n",
    "                indices_test.append(grouped_index[n_trainval])\n",
    "            \n",
    "\n",
    "        self._drop_unused_col()\n",
    "        next_df = [self.inter_feat[index] for index in [indices_train, indices_val, indices_test]]\n",
    "        next_ds = [self.copy(_) for _ in next_df]\n",
    "        return next_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='NPE'\n",
    "dataset='ml-100k'\n",
    "\n",
    "config_dict = {\n",
    "    'eval_args': {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"CO\": '886349689'},\n",
    "        \"group_by\": 'user_id'\n",
    "    },\n",
    "    'train_neg_sample_args': None\n",
    "}\n",
    "\n",
    "config = Config(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    config_dict=config_dict\n",
    ")\n",
    "\n",
    "# Set model_type as type of TimeCutoffDataset\n",
    "config['MODEL_TYPE'] = MODELTYPE_CUTOFF\n",
    "dataset = TimeCutoffDataset(config)\n",
    "train_dataset, val_dataset, test_dataset = dataset.build()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
