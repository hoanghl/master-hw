{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='NPE'\n",
    "dataset='ml-100k'\n",
    "\n",
    "config_dict = {\n",
    "    'eval_args': {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"RS\": [0.8, 0.1, 0.1]},\n",
    "        \"group_by\": None\n",
    "    },\n",
    "    'train_neg_sample_args': None\n",
    "}\n",
    "\n",
    "config = Config(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    config_dict=config_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoanghu/miniforge3/envs/py/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/hoanghu/miniforge3/envs/py/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "# train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "model_type = config[\"MODEL_TYPE\"]\n",
    "built_datasets = dataset.build()\n",
    "train_dataset, valid_dataset, test_dataset = built_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.1585e-07, 2.3704e-06, 3.8250e-06,  ..., 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.inter_feat.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.1585e-07, 2.3704e-06, 3.8250e-06,  ..., 7.8184e-01, 7.8184e-01,\n",
       "        7.8184e-01])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.inter_feat.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7818, 0.7818, 0.7818,  ..., 0.8974, 0.8974, 0.8974])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.inter_feat.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8974, 0.8974, 0.8974,  ..., 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.inter_feat.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The batch_size of interaction: 9905\n",
       "    user_id, torch.Size([9905]), cpu, torch.int64\n",
       "    item_id, torch.Size([9905]), cpu, torch.int64\n",
       "    rating, torch.Size([9905]), cpu, torch.float32\n",
       "    timestamp, torch.Size([9905]), cpu, torch.float32\n",
       "    item_length, torch.Size([9905]), cpu, torch.int64\n",
       "    item_id_list, torch.Size([9905, 50]), cpu, torch.int64\n",
       "    rating_list, torch.Size([9905, 50]), cpu, torch.float32\n",
       "    timestamp_list, torch.Size([9905, 50]), cpu, torch.float32\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.inter_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(test_dataset)):\n",
    "    if test_dataset.inter_feat.timestamp[i] - test_dataset.inter_feat.timestamp[i - 1] < 0:\n",
    "        print(\"not increased\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement time cutoff Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from recbole.data.dataset import Dataset\n",
    "from recbole.utils import (\n",
    "    FeatureType,\n",
    "    set_color,\n",
    ")\n",
    "\n",
    "class TimeCutoffDataset(Dataset):\n",
    "    def __init__(self, config):\n",
    "        self.timestamp_max, self.timestamp_min = 0., 0.\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "    def _normalize(self):\n",
    "\n",
    "        ## TODO: HoangLe [Jun-05]: Find the timestamp column and save the max/min\n",
    "        self.timestamp_max = max()\n",
    "        self.timestamp_max = min()\n",
    "\n",
    "\n",
    "        return super()._normalize()\n",
    "\n",
    "    def _fill_nan(self):\n",
    "        \"\"\"Missing value imputation.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.TOKEN`, missing value will be filled by\n",
    "        ``[PAD]``, which indexed as 0.\n",
    "\n",
    "        For fields with type :obj:`~recbole.utils.enum_type.FeatureType.FLOAT`, missing value will be filled by\n",
    "        the average of original data.\n",
    "\n",
    "        Note:\n",
    "            This is similar to the recbole's original implementation. The difference is the change in inplace operation to suit the pandas 3.0\n",
    "        \"\"\"\n",
    "        self.logger.debug(set_color(\"Filling nan\", \"green\"))\n",
    "\n",
    "        for feat_name in self.feat_name_list:\n",
    "            feat = getattr(self, feat_name)\n",
    "            for field in feat:\n",
    "                ftype = self.field2type[field]\n",
    "                if ftype == FeatureType.TOKEN:\n",
    "                    feat[field] = feat[field].fillna(value=0)\n",
    "                elif ftype == FeatureType.FLOAT:\n",
    "                    feat[field] = feat[field].fillna(value=feat[field].mean())\n",
    "                else:\n",
    "                    dtype = np.int64 if ftype == FeatureType.TOKEN_SEQ else np.float\n",
    "                    feat[field] = feat[field].apply(\n",
    "                        lambda x: (\n",
    "                            np.array([], dtype=dtype) if isinstance(x, float) else x\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    def build(self):\n",
    "        self._change_feat_format()\n",
    "\n",
    "        if self.benchmark_filename_list is not None:\n",
    "            super().build()\n",
    "\n",
    "        # ordering\n",
    "        ordering_args = self.config[\"eval_args\"][\"order\"]\n",
    "        if ordering_args == \"TO\":\n",
    "            self.sort(by=self.time_field)\n",
    "        else:\n",
    "            raise AssertionError(\"The ordering_method must be 'TO.\")\n",
    "\n",
    "        # splitting & grouping\n",
    "        split_args = self.config[\"eval_args\"][\"split\"]\n",
    "        if split_args is None:\n",
    "            raise ValueError(\"The split_args in eval_args should not be None.\")\n",
    "        if not isinstance(split_args, dict):\n",
    "            raise ValueError(f\"The split_args [{split_args}] should be a dict.\")\n",
    "\n",
    "        split_mode = list(split_args.keys())[0]\n",
    "        assert len(split_args.keys()) == 1\n",
    "        if split_mode != \"CO\":\n",
    "            raise NotImplementedError(\"The split_mode must be 'CO'.\")\n",
    "        elif split_mode == \"CO\":\n",
    "            cutoff = split_args[\"RS\"]\n",
    "            # NOTE: HoangLe [Jun-05]: cutoff may come with different types: string, datetime\n",
    "\n",
    "            group_by = self.config[\"eval_args\"][\"group_by\"]\n",
    "            datasets = self.split_by_cuttoff(cutoff=cutoff, group_by=group_by)\n",
    "    \n",
    "        \n",
    "        return datasets\n",
    "\n",
    "    def split_by_cuttoff(self, cutoff: str, group_by: str) -> list[Dataset]:\n",
    "        \"\"\"Split the interations by cutoff date\n",
    "\n",
    "        Args:\n",
    "            cutoff (str): cutoff date\n",
    "            group_by (str): field to group by, usually the user_id\n",
    "\n",
    "        Returns:\n",
    "            list[Dataset]: list of training/validation/testing dataset, whose interaction features has been split.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: HoangLe [Jun-05]: Implement this, may follow method \n",
    "        \n",
    "        self.logger.debug(f\"split by cutoff date = '{cutoff}', group_by=[{group_by}]\")\n",
    "\n",
    "        grouped_inter_feat_index = self._grouped_index(\n",
    "            self.inter_feat[group_by].numpy()\n",
    "        )\n",
    "\n",
    "        next_index = [[]]*3     # 'next_index' contains the indices for training/validation/testing dataset\n",
    "        for grouped_index in grouped_inter_feat_index:\n",
    "            # Split the grouped_index into into train/validation/test\n",
    "\n",
    "            train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "            ## TODO: HoangLe [Jun-05]: Investivate how to access 'timestamp' and how to split the self.inter_feat using cutoff\n",
    "            split_ids = self._calcu_split_ids(tot=tot_cnt, ratios=ratios)\n",
    "            for index, start, end in zip(\n",
    "                next_index, [0] + split_ids, split_ids + [tot_cnt]\n",
    "            ):\n",
    "                index.extend(grouped_index[start:end])\n",
    "\n",
    "        self._drop_unused_col()\n",
    "        next_df = [self.inter_feat[index] for index in next_index]\n",
    "        next_ds = [self.copy(_) for _ in next_df]\n",
    "        return next_ds"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
