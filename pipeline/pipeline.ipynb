{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from logging import getLogger\n",
    "\n",
    "from recbole.quick_start import run_recbole\n",
    "# from recbole.quick_start import objective_function\n",
    "from recbole.config import Config\n",
    "from recbole.data import data_preparation, create_dataset\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.utils import (\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    # init_logger,\n",
    ")\n",
    "# from loguru import logger\n",
    "\n",
    "import utils\n",
    "from real_temporal import TimeCutoffDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Declarations & Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Define flags and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_TimeCutoff = True\n",
    "reproducible = True\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Define configurations\n",
    "\n",
    "Configuration for data, model, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    # For model\n",
    "    'model': \"NPE\",\n",
    "    'embedding_size': 64,\n",
    "    'dropout_prob': 0.3,\n",
    "    'loss_type': \"CE\",\n",
    "\n",
    "    # For data\n",
    "    'dataset': 'ml-100k',\n",
    "    'load_col': {\"inter\": ['user_id', 'item_id', 'timestamp']},\n",
    "    'use_TimeCutoff': use_TimeCutoff,\n",
    "\n",
    "    # For training\n",
    "    'epochs': 500,\n",
    "    'train_batch_size': 4096,\n",
    "    'learning_rate': 1e-3,\n",
    "    'train_neg_sample_args': None,\n",
    "    \n",
    "    # For evaluation\n",
    "    'eval_batch_size': 4096,\n",
    "    'metrics': [\"Recall\", \"MRR\", \"NDCG\", \"Hit\", \"Precision\"],\n",
    "    'topk': 10,\n",
    "    'valid_metric': 'MRR@10',\n",
    "\n",
    "    # Environment\n",
    "    'checkpoint_dir': utils.get_path_dir_ckpt(),\n",
    "    'device': 'mps',\n",
    "    'show_progress': True,\n",
    "    'reproducibility': reproducible,\n",
    "    'seed': seed,\n",
    "}\n",
    "\n",
    "if use_TimeCutoff is True:\n",
    "    config_dict = {\n",
    "        **config_dict,\n",
    "        'eval_args': {\n",
    "            \"order\": \"TO\",\n",
    "            \"split\": {\"CO\": '886349689'},\n",
    "            \"group_by\": 'user_id'\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    config_dict = {\n",
    "        **config_dict,\n",
    "        'eval_args': {\n",
    "            \"order\": \"TO\",\n",
    "            \"split\": { \"LS\": \"valid_and_test\" },\n",
    "            \"group_by\": None\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Declare necessary components for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_dict=config_dict)\n",
    "\n",
    "# Define data related things\n",
    "if use_TimeCutoff:\n",
    "    dataset = TimeCutoffDataset(config)\n",
    "else:\n",
    "    dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# Define model\n",
    "model_name = config['model']\n",
    "model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "# Define trainer\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-18 23:13:33.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1m\n",
      "\u001b[1;35mGeneral Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
      "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 42\u001b[0m\n",
      "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
      "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m /Users/macos/miniforge3/envs/py/lib/python3.10/site-packages/recbole/config/../dataset_example/ml-100k\u001b[0m\n",
      "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m logs/Jun18_231331/ckpts\u001b[0m\n",
      "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\n",
      "\u001b[1;35mTraining Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 500\u001b[0m\n",
      "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
      "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
      "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
      "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
      "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
      "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
      "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
      "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mEvaluation Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'CO': '886349689'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
      "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\u001b[0m\n",
      "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10]\u001b[0m\n",
      "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m MRR@10\u001b[0m\n",
      "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
      "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mDataset Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
      "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
      "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
      "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
      "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
      "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
      "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
      "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
      "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id', 'timestamp']}\u001b[0m\n",
      "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
      "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
      "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
      "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
      "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
      "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
      "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
      "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
      "\u001b[1;36mkg_reverse_r\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mentity_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrelation_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\n",
      "\u001b[1;35mOther Hyper Parameters: \n",
      "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
      "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m64\u001b[0m\n",
      "\u001b[1;36mloss_type\u001b[0m = \u001b[1;33mCE\u001b[0m\n",
      "\u001b[1;36mdropout_prob\u001b[0m = \u001b[1;33m0.3\u001b[0m\n",
      "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
      "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.SEQUENTIAL\u001b[0m\n",
      "\u001b[1;36muse_TimeCutoff\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcpu\u001b[0m\n",
      "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.POINTWISE\u001b[0m\n",
      "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
      "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2024-06-18 23:13:33.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1m\u001b[1;35mml-100k\u001b[0m\n",
      "\u001b[1;34mThe number of users\u001b[0m: 944\n",
      "\u001b[1;34mAverage actions of users\u001b[0m: 105.04453870625663\n",
      "\u001b[1;34mThe number of items\u001b[0m: 1683\n",
      "\u001b[1;34mAverage actions of items\u001b[0m: 58.892390011890605\n",
      "\u001b[1;34mThe number of inters\u001b[0m: 99057\n",
      "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 93.76510619656183%\n",
      "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'item_id_list', 'timestamp_list', 'item_length']\u001b[0m\n",
      "\u001b[32m2024-06-18 23:13:33.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mNPE(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (embedding_seq_item): Embedding(1683, 64, padding_idx=0)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\u001b[1;34m\n",
      "Trainable parameters\u001b[0m: 275840\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === Config === \n",
      " === Dataset === \n",
      " === Model === \n"
     ]
    }
   ],
   "source": [
    "# init_logger(config)\n",
    "logger = utils.get_logger()\n",
    "# logger.add(utils.get_path_log())\n",
    "\n",
    "print(\" === Config === \")\n",
    "logger.info(config)\n",
    "\n",
    "print(\" === Dataset === \")\n",
    "logger.info(dataset)\n",
    "\n",
    "print(\" === Model === \")\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 20.50it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 186.58it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     1\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 21.70it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 170.56it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     2\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.81it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 229.15it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     3\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 21.20it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 196.20it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     4\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 23.05it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 225.99it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     5\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.71it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 219.79it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     6\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.49it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 214.83it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     7\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.88it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 208.42it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     8\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.74it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 221.55it/s]\u001b[0m\n",
      "\u001b[1;35mTrain     9\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 21.46it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 244.32it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    10\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.61it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 208.86it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    11\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 20.62it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 229.52it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    12\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 20.66it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 219.78it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    13\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 23.35it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 242.84it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    14\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 21.83it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 205.30it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    15\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.99it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 210.40it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    16\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 23.00it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 219.84it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    17\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 23.13it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 182.62it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    18\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.60it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 206.44it/s]\u001b[0m\n",
      "\u001b[1;35mTrain    19\u001b[0m: 100%|██████████████████████████████████████████████████| 17/17 [00:00<00:00, 22.13it/s]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|████████████████████████████████████████████████████| 1/1 [00:00<00:00, 89.81it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Validation result\n",
      "best_valid_score: 0.0183\n",
      "recall@10      : 0.0603\n",
      "mrr@10         : 0.0183\n",
      "ndcg@10        : 0.0279\n",
      "hit@10         : 0.0603\n",
      "precision@10   : 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, \n",
    "    valid_data,\n",
    "    verbose=True,\n",
    "    show_progress=config[\"show_progress\"]\n",
    ")\n",
    "\n",
    "print(\"** Validation result\")\n",
    "print(f\"best_valid_score: {best_valid_score:.4f}\")\n",
    "for metric, val in best_valid_result.items():\n",
    "    print(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Test result\n",
      "recall@10      : 0.0079\n",
      "mrr@10         : 0.0010\n",
      "ndcg@10        : 0.0025\n",
      "hit@10         : 0.0079\n",
      "precision@10   : 0.0008\n"
     ]
    }
   ],
   "source": [
    "test_result = trainer.evaluate(test_data)\n",
    "\n",
    "print(\"** Test result\")\n",
    "for metric, val in test_result.items():\n",
    "    print(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tune hyper params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Define hyper params and object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'loguniform': {\n",
    "        'learning_rate': [-8, 0]\n",
    "    },\n",
    "    'choice': {\n",
    "        'embedding_size': [64],\n",
    "        'dropout_prob': [0.2, 0.3, .5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    config = Config(\n",
    "        config_dict=config_dict,\n",
    "        config_file_list=config_file_list,\n",
    "    )\n",
    "\n",
    "    # Define data related things\n",
    "    if use_TimeCutoff:\n",
    "        dataset = TimeCutoffDataset(config)\n",
    "    else:\n",
    "        dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Define model\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "    # Define trainer\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "    # Start training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)\n",
    "\n",
    "    # Start evaluating\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Save config as yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(utils.get_path_conf(), 'w+') as f:\n",
    "    yaml.dump(config_dict, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Start tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                   \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.0641808729888726}\n",
      "current best valid score: 0.0171                      \n",
      "current best valid result:                            \n",
      "OrderedDict([('recall@10', 0.0541), ('mrr@10', 0.0171), ('ndcg@10', 0.0255), ('hit@10', 0.0541), ('precision@10', 0.0054)])\n",
      "current test result:                                  \n",
      "OrderedDict([('recall@10', 0.0), ('mrr@10', 0.0), ('ndcg@10', 0.0), ('hit@10', 0.0), ('precision@10', 0.0)])\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.01153580169569852}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.001328144472054237}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.05453059693665552}\n",
      "current best valid score: 0.0229                                     \n",
      "current best valid result:                                           \n",
      "OrderedDict([('recall@10', 0.0526), ('mrr@10', 0.0229), ('ndcg@10', 0.0297), ('hit@10', 0.0526), ('precision@10', 0.0053)])\n",
      "current test result:                                                 \n",
      "OrderedDict([('recall@10', 0.0157), ('mrr@10', 0.0118), ('ndcg@10', 0.0128), ('hit@10', 0.0157), ('precision@10', 0.0016)])\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.7076141548789925}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.5, 'embedding_size': 64, 'learning_rate': 0.019947612433945307}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.3, 'embedding_size': 64, 'learning_rate': 0.0009829984775225958}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.11898131969865439}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.3, 'embedding_size': 64, 'learning_rate': 0.0012367265149822414}\n",
      "running parameters:                                                  \n",
      "{'dropout_prob': 0.3, 'embedding_size': 64, 'learning_rate': 0.029469117828326598}\n",
      "100%|██████████| 10/10 [02:44<00:00, 16.46s/trial, best loss: -0.0229]\n"
     ]
    }
   ],
   "source": [
    "tuning_algo = \"bayes\"\n",
    "early_stop = 10\n",
    "max_evals = 10\n",
    "\n",
    "hp = HyperTuning(\n",
    "    objective_function=objective_function,\n",
    "    algo=tuning_algo,\n",
    "    early_stop=early_stop,\n",
    "    max_evals=max_evals,\n",
    "    params_dict=hyper_params,\n",
    "    fixed_config_file_list=[utils.get_path_conf()]\n",
    ")\n",
    "\n",
    "\n",
    "hp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Export tunning result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'dropout_prob': 0.2, 'embedding_size': 64, 'learning_rate': 0.05453059693665552}\n",
      "best result: \n",
      "{'model': 'NPE', 'best_valid_score': 0.0229, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.0526), ('mrr@10', 0.0229), ('ndcg@10', 0.0297), ('hit@10', 0.0526), ('precision@10', 0.0053)]), 'test_result': OrderedDict([('recall@10', 0.0157), ('mrr@10', 0.0118), ('ndcg@10', 0.0128), ('hit@10', 0.0157), ('precision@10', 0.0016)])}\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "print('best params: ', hp.best_params)\n",
    "\n",
    "# print best result\n",
    "print('best result: ')\n",
    "print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "# export to JSON file\n",
    "tune_result = {\n",
    "    'best_params': hp.best_params,\n",
    "    'best_result': hp.params2result[hp.params2str(hp.best_params)]\n",
    "}\n",
    "with open(utils.get_path_tune_log(), \"w+\") as f:\n",
    "    json.dump(tune_result, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                    \n",
      "{'embedding_size': 128, 'learning_rate': 0.012213481366920161, 'mlp_hidden_size': '[128,128]'}\n",
      "current best valid score: 0.0164                       \n",
      "current best valid result:                             \n",
      "OrderedDict([('recall@10', 0.0668), ('mrr@10', 0.0164), ('ndcg@10', 0.0279), ('hit@10', 0.0668), ('precision@10', 0.0067)])\n",
      "current test result:                                   \n",
      "OrderedDict([('recall@10', 0.0435), ('mrr@10', 0.008), ('ndcg@10', 0.0161), ('hit@10', 0.0435), ('precision@10', 0.0043)])\n",
      "running parameters:                                                     \n",
      "{'embedding_size': 64, 'learning_rate': 0.09821758837521936, 'mlp_hidden_size': '[128,128]'}\n",
      "current best valid score: 0.0218                                        \n",
      "current best valid result:                                              \n",
      "OrderedDict([('recall@10', 0.0647), ('mrr@10', 0.0218), ('ndcg@10', 0.0317), ('hit@10', 0.0647), ('precision@10', 0.0065)])\n",
      "current test result:                                                    \n",
      "OrderedDict([('recall@10', 0.053), ('mrr@10', 0.0169), ('ndcg@10', 0.0252), ('hit@10', 0.053), ('precision@10', 0.0053)])\n",
      "running parameters:                                                     \n",
      "{'embedding_size': 64, 'learning_rate': 0.00469754128962849, 'mlp_hidden_size': '[64,64,64]'}\n",
      "running parameters:                                                     \n",
      "{'embedding_size': 64, 'learning_rate': 0.7871671871908642, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 96, 'learning_rate': 0.0004863243520253361, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.0014050888598820753, 'mlp_hidden_size': '[64,64,64]'}\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.5007048169076744, 'mlp_hidden_size': '[64,64,64]'}\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.029514916305062155, 'mlp_hidden_size': '[64,64,64]'}\n",
      "current best valid score: 0.0254                                      \n",
      "current best valid result:                                            \n",
      "OrderedDict([('recall@10', 0.0795), ('mrr@10', 0.0254), ('ndcg@10', 0.0377), ('hit@10', 0.0795), ('precision@10', 0.008)])\n",
      "current test result:                                                  \n",
      "OrderedDict([('recall@10', 0.0594), ('mrr@10', 0.0199), ('ndcg@10', 0.0289), ('hit@10', 0.0594), ('precision@10', 0.0059)])\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.27582899246303183, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.0005425481744912389, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                    \n",
      "{'embedding_size': 96, 'learning_rate': 0.005205784163202396, 'mlp_hidden_size': '[64,64,64]'}\n",
      "running parameters:                                                    \n",
      "{'embedding_size': 96, 'learning_rate': 0.005317261870117616, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                    \n",
      "{'embedding_size': 128, 'learning_rate': 0.0015915130136012967, 'mlp_hidden_size': '[64,64,64]'}\n",
      "running parameters:                                                    \n",
      "{'embedding_size': 128, 'learning_rate': 0.003636553061380148, 'mlp_hidden_size': '[128,128]'}\n",
      "running parameters:                                                    \n",
      "{'embedding_size': 64, 'learning_rate': 0.0005597694578373445, 'mlp_hidden_size': '[128,128]'}\n",
      " 14%|█▍        | 14/100 [06:06<37:31, 26.18s/trial, best loss: -0.0254]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     47\u001b[0m hp \u001b[38;5;241m=\u001b[39m HyperTuning(\n\u001b[1;32m     48\u001b[0m     objective_function\u001b[38;5;241m=\u001b[39mobjective_function,\n\u001b[1;32m     49\u001b[0m     algo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbayes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     fixed_config_file_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.yml\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# export result to the file\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# hp.export_result(output_file='hyper_example.result')\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# # print best parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print('best result: ')\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(hp.params2result[hp.params2str(hp.best_params)])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/hyper_tuning.py:412\u001b[0m, in \u001b[0;36mHyperTuning.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"begin to search the best parameters\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 412\u001b[0m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_hyper()\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/hyper_tuning.py:347\u001b[0m, in \u001b[0;36mHyperTuning.trial\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_list\u001b[38;5;241m.\u001b[39mappend(params_str)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_dict)\n\u001b[0;32m--> 347\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_config_file_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams2result[params_str] \u001b[38;5;241m=\u001b[39m result_dict\n\u001b[1;32m    349\u001b[0m model, score, bigger \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    350\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    351\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_valid_score\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    352\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_score_bigger\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    353\u001b[0m )\n",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m, in \u001b[0;36mobjective_function\u001b[0;34m(config_dict, config_file_list)\u001b[0m\n\u001b[1;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(model_name)(config, train_data\u001b[38;5;241m.\u001b[39m_dataset)\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     35\u001b[0m trainer \u001b[38;5;241m=\u001b[39m get_trainer(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])(config, model)\n\u001b[0;32m---> 36\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m test_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_valid_score\u001b[39m\u001b[38;5;124m'\u001b[39m: best_valid_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_result\u001b[39m\u001b[38;5;124m'\u001b[39m: test_result\n\u001b[1;32m     45\u001b[0m }\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     training_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 439\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_loss, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_loss\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     training_end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/trainer.py:245\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sync_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_grad_loss()\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_amp):\n\u001b[0;32m--> 245\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(losses, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    248\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(losses)\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/model/sequential_recommender/npe.py:94\u001b[0m, in \u001b[0;36mNPE.calculate_loss\u001b[0;34m(self, interaction)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# self.loss_type = 'CE'\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     test_item_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embedding\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 94\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(seq_output, \u001b[43mtest_item_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     95\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fct(logits, pos_items)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/torch/fx/traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/traceback.py:383\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m--> 383\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/traceback.py:304\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m linecache\u001b[38;5;241m.\u001b[39mgetline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from real_temporal import run_recbole_with_TimeCutoff, TimeCutoffDataset\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "# from recbole.quick_start import objective_function\n",
    "from recbole.config import Config\n",
    "# from recbole.quick_start import run_recbole\n",
    "from recbole.data import (\n",
    "    create_dataset,\n",
    "     data_preparation,\n",
    ")\n",
    "\n",
    "from recbole.utils import (\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    init_seed,\n",
    ")\n",
    "\n",
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    model_name = 'NPE'\n",
    "    dataset_name = 'ml-100k'\n",
    "\n",
    "    config = Config(\n",
    "        config_dict=config_dict,\n",
    "        config_file_list=config_file_list,\n",
    "        model=model_name,\n",
    "        dataset=dataset_name\n",
    "    )\n",
    "    # init_seed(config['seed'])\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }\n",
    "\n",
    "hp = HyperTuning(\n",
    "    objective_function=objective_function,\n",
    "    algo='bayes',\n",
    "    early_stop=10,\n",
    "    max_evals=100,\n",
    "    params_file='model.hyper',\n",
    "    fixed_config_file_list=['test.yml']\n",
    ")\n",
    "\n",
    "# run\n",
    "hp.run()\n",
    "# export result to the file\n",
    "# hp.export_result(output_file='hyper_example.result')\n",
    "# # print best parameters\n",
    "# print('best params: ', hp.best_params)\n",
    "# # print best result\n",
    "# print('best result: ')\n",
    "# print(hp.params2result[hp.params2str(hp.best_params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000621 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 0 trials\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                    \n",
      "{'embedding_size': 64, 'learning_rate': 0.0005927902936991883, 'mlp_hidden_size': '[128,128]'}\n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-12-52.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.0463                       \n",
      "current best valid result:                             \n",
      "OrderedDict([('recall@10', 0.1262), ('mrr@10', 0.0463), ('ndcg@10', 0.0647), ('hit@10', 0.1262), ('precision@10', 0.0126)])\n",
      "current test result:                                   \n",
      "OrderedDict([('recall@10', 0.1145), ('mrr@10', 0.0473), ('ndcg@10', 0.0629), ('hit@10', 0.1145), ('precision@10', 0.0115)])\n",
      "  1%|          | 1/100 [00:01<02:37,  1.59s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000557 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 1/1 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 128, 'learning_rate': 0.004837377747388512, 'mlp_hidden_size': '[128,128]'}\n",
      "  1%|          | 1/100 [00:01<02:37,  1.59s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-12-54.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:03<02:36,  1.59s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000520 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 2/2 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 96, 'learning_rate': 0.04969285232271135, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  2%|▏         | 2/100 [00:03<02:36,  1.59s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-12-55.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:04<02:26,  1.51s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000590 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 3/3 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 128, 'learning_rate': 0.9011798093382721, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  3%|▎         | 3/100 [00:04<02:26,  1.51s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-12-57.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:06<02:25,  1.51s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000479 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 4/4 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.002760427052316751, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  4%|▍         | 4/100 [00:06<02:25,  1.51s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-12-59.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:07<02:25,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:12    INFO  build_posterior_wrapper took 0.000504 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:12    INFO  TPE using 5/5 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.10228515500215882, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  5%|▌         | 5/100 [00:07<02:25,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-13-00.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:09<02:24,  1.53s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  build_posterior_wrapper took 0.000463 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  TPE using 6/6 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 128, 'learning_rate': 0.02978502690204238, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  6%|▌         | 6/100 [00:09<02:24,  1.53s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-13-02.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:10<02:23,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  build_posterior_wrapper took 0.000477 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  TPE using 7/7 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 96, 'learning_rate': 0.001566641566088578, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  7%|▋         | 7/100 [00:10<02:23,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-13-03.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:12<02:21,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  build_posterior_wrapper took 0.000474 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  TPE using 8/8 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 96, 'learning_rate': 0.0062624696339975885, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  8%|▊         | 8/100 [00:12<02:21,  1.54s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-13-05.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:13<02:23,  1.58s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  build_posterior_wrapper took 0.000442 seconds\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  TPE using 9/9 trials with best loss -0.046300\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                   \n",
      "{'embedding_size': 64, 'learning_rate': 0.05115291209207257, 'mlp_hidden_size': '[128,128]'}\n",
      "  9%|▉         | 9/100 [00:13<02:23,  1.58s/trial, best loss: -0.0463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Jun 22:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'None', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Loading model structure and parameters from saved/ItemKNN-Jun-17-2024_22-13-06.pth\u001b[0m\n",
      "\n",
      "17 Jun 22:13    INFO  Early stop triggered. Stopping iterations as condition is reach.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:15<02:18,  1.54s/trial, best loss: -0.0463]\n",
      "best params:  {'embedding_size': 64, 'learning_rate': 0.0005927902936991883, 'mlp_hidden_size': '[128,128]'}\n",
      "best result: \n",
      "{'model': 'ItemKNN', 'best_valid_score': 0.0463, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.1262), ('mrr@10', 0.0463), ('ndcg@10', 0.0647), ('hit@10', 0.1262), ('precision@10', 0.0126)]), 'test_result': OrderedDict([('recall@10', 0.1145), ('mrr@10', 0.0473), ('ndcg@10', 0.0629), ('hit@10', 0.1145), ('precision@10', 0.0115)])}\n"
     ]
    }
   ],
   "source": [
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "hp = HyperTuning(objective_function=objective_function, algo='bayes', early_stop=10,\n",
    "                max_evals=100, params_file='model.hyper', fixed_config_file_list=['test.yml'])\n",
    "\n",
    "# run\n",
    "hp.run()\n",
    "# export result to the file\n",
    "hp.export_result(output_file='hyper_example.result')\n",
    "# print best parameters\n",
    "print('best params: ', hp.best_params)\n",
    "# print best result\n",
    "print('best result: ')\n",
    "print(hp.params2result[hp.params2str(hp.best_params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Offline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_MODES = {\n",
    "    \"temporal\": \"TO\",\n",
    "    \"leave1out\": \"LS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_eval_models = [EVAL_MODES[k] for k in [\"temporal\", \"leave1out\"]]\n",
    "selected_eval_metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
    "selected_topk = 10\n",
    "\n",
    "eval_args = {\n",
    "    \"order\": \"TO\",\n",
    "    \"split\": {\n",
    "        'LS': \"valid_and_test\"\n",
    "    },\n",
    "    \"group_by\": None\n",
    "}\n",
    "\n",
    "config_dict = {\n",
    "    'eval_args': eval_args,\n",
    "    # 'train_neg_sample_args': None,\n",
    "}\n",
    "\n",
    "run_recbole(model=model, dataset=data, config_dict=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_recbole(model='NPE', dataset='ml-100k', config_file_list=['test.yml'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
