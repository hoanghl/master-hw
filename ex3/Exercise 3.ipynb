{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e708e6",
   "metadata": {},
   "source": [
    "## Exercise 3.1 (4 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa4f82",
   "metadata": {},
   "source": [
    "Please find the 3 sets of images provided in the Moodle page of this week's exercise. The three image sets (A,B and C) contain pictures taken of a camera calibration checkerboard pattern with a square size of 3cm.\n",
    "\n",
    "1) Write a function using built-in OpenCV methods that computes the intrinsic camera calibration matrix and distortion matrix from a given set of calibration images.\n",
    "\n",
    "2) Apply that function to all three sets of images and observe the results. Based on the results for the intrinsic and distortion matrix, discuss what type of camera or lens was used to capture the different image sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0263f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images A:\n",
      "[[3440.39401167    0.         1606.30026185]\n",
      " [   0.         3438.45441335 1924.66106917]\n",
      " [   0.            0.            1.        ]]\n",
      "[[ 0.20366693 -0.89153343 -0.00669965  0.0097696   2.01645186]]\n",
      "\n",
      "Images B:\n",
      "[[1707.80289324    0.         1477.7231122 ]\n",
      " [   0.         1704.50604179 1989.87378206]\n",
      " [   0.            0.            1.        ]]\n",
      "[[-0.00571021  0.01908916 -0.00171764 -0.00362863 -0.00341247]]\n",
      "\n",
      "Images C:\n",
      "[[7567.61688346    0.         1286.82390667]\n",
      " [   0.         7594.36409244 2015.22836071]\n",
      " [   0.            0.            1.        ]]\n",
      "[[ -0.17233294   9.05892372  -0.01414267  -0.00978813 -61.28909561]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "def calibrate(img_path):\n",
    "    matrix = None\n",
    "    distortion = None\n",
    "\n",
    "    nx, ny = 8, 6\n",
    "\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "    # objp *= 30\n",
    "    \n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    images = glob.glob(\"{}/*.jpeg\".format(img_path))\n",
    "\n",
    "    for filename in images:\n",
    "        image = cv2.imread(filename)\n",
    "        grayColor = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(grayColor, (nx, ny), None)\n",
    "    \n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret is True:\n",
    "            objpoints.append(objp)\n",
    "    \n",
    "            corners2 = cv2.cornerSubPix(grayColor,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, grayColor.shape[::-1], None, None)\n",
    "    matrix, distortion = mtx, dist\n",
    "\n",
    "    return matrix, distortion\n",
    "\n",
    "\n",
    "print(\"Images A:\")\n",
    "matrix, distortion = calibrate(\"images_A\")\n",
    "print(matrix)\n",
    "print(distortion)\n",
    "print()\n",
    "\n",
    "print(\"Images B:\")\n",
    "matrix, distortion = calibrate(\"images_B\")\n",
    "print(matrix)\n",
    "print(distortion)\n",
    "print()\n",
    "\n",
    "print(\"Images C:\")\n",
    "matrix, distortion = calibrate(\"images_C\")\n",
    "print(matrix)\n",
    "print(distortion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f3424",
   "metadata": {},
   "source": [
    "### Answer for question 2\n",
    "\n",
    "From distortion matrix, we can see that with Image set B, the calculated distortion coefficients are nearly equal to 0, so the images in set B are taken from normal camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373fca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f5e647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_A/0FD77AFE-FDC1-4E5E-AD57-86B8B1B29738.jpeg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"images_A\"\n",
    "\n",
    "nx, ny = 8, 6\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "objp = np.zeros((nx * ny, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "# objp *= 30\n",
    "\n",
    "\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob(\"{}/*.jpeg\".format(img_path))\n",
    "\n",
    "for filename in images:\n",
    "    image = cv2.imread(filename)\n",
    "    grayColor = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(grayColor, (nx, ny), None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret is True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(grayColor,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, grayColor.shape[::-1], None, None)\n",
    "\n",
    "print(filename)\n",
    "\n",
    "image = cv2.imread(filename)\n",
    "h,  w = image.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst = cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n",
    " \n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "# plt.imshow(dst)\n",
    "cv2.imwrite('calibresult.png', dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f694728",
   "metadata": {},
   "source": [
    "## Exercise 3.2 (4 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f008f",
   "metadata": {},
   "source": [
    "1) Explain how the Hough Transform works, focusing on its application to line detection in images. Discuss why the Hough Transform is particularly useful for detecting lines in noisy images or images with missing data. Additionally, explain the limitations of the Hough Transform and potential methods to overcome these limitations.\n",
    "\n",
    "2)  We provided you example images from the Berkeley Segmentation Dataset. Implement the Hough Transform for line detection by yourself (You may only use the openCV function to check if your solution is correct). Instead of using the default parameters, customize the parameters (e.g., resolution of the parameter space, threshold values for line detection, minimum line length, maximum line gap) to optimize edge detection for the given set of images. Report your observations: which parameters influenced which behaviour in the output? Also report which parameter configuration resembles closest an object segmentation in the test images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35235d7e",
   "metadata": {},
   "source": [
    "### Answer for question 1\n",
    "\n",
    "Hough transform employ Voting mechanism in parameter space to detect line from detected edges.\n",
    "If the edge is indeed a part of a line, Voting mechanism in Hough transform will increase the likelihood of the line. Noise, on the other hand, doesn't constitute to any particular line, so the positions in accumulator affected by noise are less likely to become lines. That's why Hough transform is noise-resistant. In the occlusion case, even part of real line is occluded, other parts of the line can still increase the likelihood of the line in the accumulator and therefore the line can still be detected eventually.\n",
    "\n",
    "One of limitation of Hough Transform is the running time. Standard Hough Transform has large running time complexity. Therefore, Probabilistic Hough Transform is proposed to mitigate this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8b3e245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21077\n",
      "38082\n",
      "69020\n",
      "37073\n",
      "33039\n",
      "41069\n"
     ]
    }
   ],
   "source": [
    "#2)\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def apply_hough_transform(image, rho=1, theta=np.pi/180, threshold=140):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edges_coord = np.vstack(np.where(edges > 0)).T.tolist()\n",
    "\n",
    "    h, w = gray.shape\n",
    "    diag = np.sqrt(h**2 + w**2)\n",
    "\n",
    "    N_rho = np.floor(diag / rho).astype(np.int32)\n",
    "    N_theta = np.floor(np.pi / theta).astype(np.int32)\n",
    "\n",
    "    H = np.zeros((N_theta + 1, N_rho + 1))\n",
    "\n",
    "    for (y, x) in edges_coord:\n",
    "        for i_theta in range(0, N_theta + 1):\n",
    "            i_rho = np.round(x * np.cos(i_theta) + y * np.sin(i_theta)).astype(np.int32)\n",
    "\n",
    "            H[i_theta, i_rho] += 1\n",
    "\n",
    "    lines = np.vstack(np.where(H >= threshold)).T\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "RHO = 1\n",
    "THETA = np.pi / 150.\n",
    "threshold = 120\n",
    "\n",
    "images = Path(\"segmentation_images\").glob(\"*.jpg\")\n",
    "dir_out = Path(\"line_detections\")\n",
    "dir_out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for filename in images:\n",
    "    print(filename.stem)\n",
    "\n",
    "    image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    lines = apply_hough_transform(image, RHO, THETA, threshold)\n",
    "\n",
    "    # Draw lines\n",
    "    for (theta, rho) in lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "\n",
    "        cv2.line(image, pt1, pt2, (0,0,255), 3, cv2.LINE_AA)\n",
    "\n",
    "    path_out = dir_out / f\"{filename.stem}.png\"\n",
    "    cv2.imwrite(path_out.as_posix(), image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718efee3",
   "metadata": {},
   "source": [
    "### Answer for question 2\n",
    "\n",
    "Among 3 parameters:\n",
    "- `threshold` affects the likelihood of the lines. Therefore, higher `threshold` means less lines detected\n",
    "- `rho` and `theta` are the resolution. Therefore, higher value of these parameters mean less accurate the lines are"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
