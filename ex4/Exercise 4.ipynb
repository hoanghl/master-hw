{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3611ce15",
   "metadata": {},
   "source": [
    "## Exercise 4.1 (4 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32e3dc",
   "metadata": {},
   "source": [
    "### Epipolar Geometry\n",
    "\n",
    "1. In your own words, explain the following terms:\n",
    "   - Epipole\n",
    "   - Epipolar line\n",
    "   - Epipolar plane\n",
    "\n",
    "\n",
    "2.  Explain what the epipolar constraint is. Why does a point in one image have a corresponding geometric relationship with the epipolar line in the other view?\n",
    "\n",
    "\n",
    "3.  In simple terms, describe the role of the fundamental matrix **F**. Why is it important in epipolar geometry, and how does it relate two camera views?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71003880",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Given object `X` and 2 camera `o1` and `o2`. Call the Image plane 1, 2 as the image plane of camera `o1` and `o2` respectiveline. Denote `x1` and `x2` as the image of object `X` on Image plane 1 and 2 respectively.\n",
    "\n",
    "1.\n",
    "\n",
    "- Epipoles `e1` and `e2` are image of a camera on image plane of another camera.\n",
    "- Epipolar plane `pi` is the plane contains 2 cameras and object `X`\n",
    "- Epipolar lines `l1` and `l2` are the intersection of Epipolar plane with each of image plane.\n",
    "\n",
    "2. Using the notations above, we define epipolar contraint is that the corresponding point `x'` of image `x1` must lie on the epipolar line `l2` and vice versa.\n",
    "\n",
    "In the ray `o1X`, all points will result the image `x1` on the Image plane 1. However, each of these points will result different images on Image plane 2. So, the image `x1` relates to the whole epipolar line `l2`.\n",
    "\n",
    "3. Fundamental matrix `F` shows the relationship between 2 images of the same object in 2 different Image plane. Fundamental matrix is usefull because it enables the full reconstruction. Fundamental matrix includes not only the extrinsic info of the stereo system but also the intrinsic info of each of 2 cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9feb82c",
   "metadata": {},
   "source": [
    "## Exercise 4.2 (4 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ee36c",
   "metadata": {},
   "source": [
    "### 8-Point Algorithm\n",
    "\n",
    "In this task you are given two images (\"Corridor1.jpg\" and \"Corridor2.jpg\"). \n",
    "1) Detect and match features from those images using OpenCv's SIFT detector and OpenCV's BFFMatcher (https://docs.opencv.org/3.4/da/df5/tutorial_py_sift_intro.html and https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html)\n",
    "\n",
    "2) Implement the 8-point algorithm and compute the fundamental matrix. Normalize the 2d points before running the 8-point algorithm. \n",
    "\n",
    "3) Validate your results by drawing epipolar lines on image 2 and verify that corresponding points lie on these lines. Explain why this happens.\n",
    "\n",
    "You can find more resources on epipolar geometry in the course book “Multiple View Geometry in computer vision” by R. Hartley and A. Zisserman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56fc5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the images\n",
    "img1 = cv2.imread('Corridor1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Corridor2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Form matrix T\n",
    "h, w = img1.shape\n",
    "\n",
    "T = np.float32([\n",
    "    [2 / h, 0,      -1],\n",
    "    [0,     2 / w,  -1],\n",
    "    [0,     0,      1]\n",
    "])\n",
    "\n",
    "#########################\n",
    "# Detect matching feature\n",
    "#########################\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "\n",
    "pairs = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        # good.append(m)\n",
    "        img1_idx = m.queryIdx\n",
    "        img2_idx = m.trainIdx\n",
    "\n",
    "        y1, x1 = kp1[img1_idx].pt\n",
    "        y2, x2 = kp2[img2_idx].pt\n",
    "\n",
    "        point1, point2 = np.float32([y1, x1, 1]), np.float32([y2, x2, 1])\n",
    "        point1, point2 = T @ point1, T @ point2\n",
    "\n",
    "        pairs.append((point1, point2))\n",
    "\n",
    "#########################\n",
    "# 8-point algorithm\n",
    "#########################\n",
    "# Build constraint matrix\n",
    "rows = []\n",
    "for (p1, p2) in pairs:\n",
    "    rows.append([\n",
    "        p1[0] * p2[0],\n",
    "        p1[1] * p2[0],\n",
    "        p2[0],\n",
    "        p1[0] * p2[1],\n",
    "        p1[1] * p2[1],\n",
    "        p2[1],\n",
    "        p1[0],\n",
    "        p1[1],\n",
    "        1\n",
    "    ])\n",
    "\n",
    "A = np.float32(rows)\n",
    "\n",
    "U, D, VT = np.linalg.svd(A, full_matrices=False)\n",
    "F = VT[:, -1].reshape(3, 3).T\n",
    "U, D, VT =  np.linalg.svd(F, full_matrices=False)\n",
    "D_ = np.diag([D[1], D[2], 0])\n",
    "F = U @ D_ @ VT.T\n",
    "F = np.transpose(T) @ F @ T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e21b929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.84516674e-07,  1.57351588e-09,  8.94625187e-05],\n",
       "       [ 5.50990318e-08,  4.36262084e-09, -3.04410975e-05],\n",
       "       [ 8.97397319e-05, -6.67212964e-06, -3.89552083e-02]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd0bfab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.67279019e-05,  2.29136629e-05,  4.58280207e-02])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_ = F @ np.float32([y1, x1, 1])\n",
    "l_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a72cbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0271100124156583)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32([y2, x2, 1]).T @ F @ np.float32([y1, x1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
