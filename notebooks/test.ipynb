{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import (\n",
    "    create_dataset,\n",
    "    data_preparation,\n",
    ")\n",
    "from recbole.data.transform import construct_transform\n",
    "from recbole.utils import (\n",
    "    init_logger,\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    init_seed,\n",
    "    set_color,\n",
    "    get_flops,\n",
    "    get_environment,\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03 Jul 23:03    INFO  ['/Users/macos/miniforge3/envs/py/lib/python3.10/site-packages/ipykernel_launcher.py', '--f=/Users/macos/Library/Jupyter/runtime/kernel-v2-12367F6ZQzYVulNJz.json']\n",
      "03 Jul 23:03    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/ml-1m\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': None, 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 1024\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = False\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "dropout_prob = 0.4\n",
      "reg_weight = 0.0001\n",
      "nv = 4\n",
      "nh = 8\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "03 Jul 23:03    INFO  ml-1m\n",
      "The number of users: 6041\n",
      "Average actions of users: 165.5975165562914\n",
      "The number of items: 3707\n",
      "Average actions of items: 269.88909875876953\n",
      "The number of inters: 1000209\n",
      "The sparsity of the dataset: 95.53358229599758%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "03 Jul 23:03    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "03 Jul 23:03    INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': None, 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "03 Jul 23:03    INFO  Caser(\n",
      "  (user_embedding): Embedding(6041, 64, padding_idx=0)\n",
      "  (item_embedding): Embedding(3707, 64, padding_idx=0)\n",
      "  (conv_v): Conv2d(1, 4, kernel_size=(50, 1), stride=(1, 1))\n",
      "  (conv_h): ModuleList(\n",
      "    (0): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1))\n",
      "    (1): Conv2d(1, 8, kernel_size=(2, 64), stride=(1, 1))\n",
      "    (2): Conv2d(1, 8, kernel_size=(3, 64), stride=(1, 1))\n",
      "    (3): Conv2d(1, 8, kernel_size=(4, 64), stride=(1, 1))\n",
      "    (4): Conv2d(1, 8, kernel_size=(5, 64), stride=(1, 1))\n",
      "    (5): Conv2d(1, 8, kernel_size=(6, 64), stride=(1, 1))\n",
      "    (6): Conv2d(1, 8, kernel_size=(7, 64), stride=(1, 1))\n",
      "    (7): Conv2d(1, 8, kernel_size=(8, 64), stride=(1, 1))\n",
      "    (8): Conv2d(1, 8, kernel_size=(9, 64), stride=(1, 1))\n",
      "    (9): Conv2d(1, 8, kernel_size=(10, 64), stride=(1, 1))\n",
      "    (10): Conv2d(1, 8, kernel_size=(11, 64), stride=(1, 1))\n",
      "    (11): Conv2d(1, 8, kernel_size=(12, 64), stride=(1, 1))\n",
      "    (12): Conv2d(1, 8, kernel_size=(13, 64), stride=(1, 1))\n",
      "    (13): Conv2d(1, 8, kernel_size=(14, 64), stride=(1, 1))\n",
      "    (14): Conv2d(1, 8, kernel_size=(15, 64), stride=(1, 1))\n",
      "    (15): Conv2d(1, 8, kernel_size=(16, 64), stride=(1, 1))\n",
      "    (16): Conv2d(1, 8, kernel_size=(17, 64), stride=(1, 1))\n",
      "    (17): Conv2d(1, 8, kernel_size=(18, 64), stride=(1, 1))\n",
      "    (18): Conv2d(1, 8, kernel_size=(19, 64), stride=(1, 1))\n",
      "    (19): Conv2d(1, 8, kernel_size=(20, 64), stride=(1, 1))\n",
      "    (20): Conv2d(1, 8, kernel_size=(21, 64), stride=(1, 1))\n",
      "    (21): Conv2d(1, 8, kernel_size=(22, 64), stride=(1, 1))\n",
      "    (22): Conv2d(1, 8, kernel_size=(23, 64), stride=(1, 1))\n",
      "    (23): Conv2d(1, 8, kernel_size=(24, 64), stride=(1, 1))\n",
      "    (24): Conv2d(1, 8, kernel_size=(25, 64), stride=(1, 1))\n",
      "    (25): Conv2d(1, 8, kernel_size=(26, 64), stride=(1, 1))\n",
      "    (26): Conv2d(1, 8, kernel_size=(27, 64), stride=(1, 1))\n",
      "    (27): Conv2d(1, 8, kernel_size=(28, 64), stride=(1, 1))\n",
      "    (28): Conv2d(1, 8, kernel_size=(29, 64), stride=(1, 1))\n",
      "    (29): Conv2d(1, 8, kernel_size=(30, 64), stride=(1, 1))\n",
      "    (30): Conv2d(1, 8, kernel_size=(31, 64), stride=(1, 1))\n",
      "    (31): Conv2d(1, 8, kernel_size=(32, 64), stride=(1, 1))\n",
      "    (32): Conv2d(1, 8, kernel_size=(33, 64), stride=(1, 1))\n",
      "    (33): Conv2d(1, 8, kernel_size=(34, 64), stride=(1, 1))\n",
      "    (34): Conv2d(1, 8, kernel_size=(35, 64), stride=(1, 1))\n",
      "    (35): Conv2d(1, 8, kernel_size=(36, 64), stride=(1, 1))\n",
      "    (36): Conv2d(1, 8, kernel_size=(37, 64), stride=(1, 1))\n",
      "    (37): Conv2d(1, 8, kernel_size=(38, 64), stride=(1, 1))\n",
      "    (38): Conv2d(1, 8, kernel_size=(39, 64), stride=(1, 1))\n",
      "    (39): Conv2d(1, 8, kernel_size=(40, 64), stride=(1, 1))\n",
      "    (40): Conv2d(1, 8, kernel_size=(41, 64), stride=(1, 1))\n",
      "    (41): Conv2d(1, 8, kernel_size=(42, 64), stride=(1, 1))\n",
      "    (42): Conv2d(1, 8, kernel_size=(43, 64), stride=(1, 1))\n",
      "    (43): Conv2d(1, 8, kernel_size=(44, 64), stride=(1, 1))\n",
      "    (44): Conv2d(1, 8, kernel_size=(45, 64), stride=(1, 1))\n",
      "    (45): Conv2d(1, 8, kernel_size=(46, 64), stride=(1, 1))\n",
      "    (46): Conv2d(1, 8, kernel_size=(47, 64), stride=(1, 1))\n",
      "    (47): Conv2d(1, 8, kernel_size=(48, 64), stride=(1, 1))\n",
      "    (48): Conv2d(1, 8, kernel_size=(49, 64), stride=(1, 1))\n",
      "    (49): Conv2d(1, 8, kernel_size=(50, 64), stride=(1, 1))\n",
      "  )\n",
      "  (fc1): Linear(in_features=656, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (ac_conv): ReLU()\n",
      "  (ac_fc): ReLU()\n",
      "  (reg_loss): RegLoss()\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 1327580\n",
      "03 Jul 23:03    INFO  FLOPs: 11381504.0\n",
      "Train     0:   0%|                                                          | 0/960 [00:00<?, ?it/s]:   0%|                                                | 1/960 [00:05<1:23:33,  5.23s/it]:   0%|                                                | 2/960 [00:10<1:19:52,  5.00s/it]:   0%|▏                                               | 3/960 [00:14<1:19:04,  4.96s/it]:   0%|▏                                               | 4/960 [00:19<1:18:40,  4.94s/it]:   1%|▎                                               | 5/960 [00:24<1:17:57,  4.90s/it]:   1%|▎                                               | 6/960 [00:29<1:17:32,  4.88s/it]:   1%|▎                                               | 7/960 [00:34<1:17:11,  4.86s/it]:   1%|▍                                               | 8/960 [00:39<1:17:17,  4.87s/it]:   1%|▍                                               | 9/960 [00:44<1:17:16,  4.88s/it]:   1%|▍                                              | 10/960 [00:49<1:20:53,  5.11s/it]:   1%|▌                                              | 11/960 [00:54<1:20:07,  5.07s/it]:   1%|▌                                              | 12/960 [00:59<1:19:23,  5.03s/it]:   1%|▋                                              | 13/960 [01:04<1:18:55,  5.00s/it]:   1%|▋                                              | 14/960 [01:09<1:18:30,  4.98s/it]:   2%|▋                                              | 15/960 [01:14<1:18:30,  4.99s/it]:   2%|▊                                              | 16/960 [01:19<1:17:47,  4.94s/it]:   2%|▊                                              | 17/960 [01:24<1:17:18,  4.92s/it]:   2%|▊                                              | 17/960 [01:29<1:22:36,  5.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m      4\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# 'normalize_field': None,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_all\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# 'train_neg_sample_args': None\u001b[39;00m\n\u001b[1;32m     28\u001b[0m }\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# config = Config(\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     model=model,\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#     dataset=dataset,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# dataset = create_dataset(config)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mrun_recbole\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# dataset.inter_feat['timestamp']\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/quick_start/quick_start.py:149\u001b[0m, in \u001b[0;36mrun_recbole\u001b[0;34m(model, dataset, config_file_list, config_dict, saved, queue)\u001b[0m\n\u001b[1;32m    146\u001b[0m trainer \u001b[38;5;241m=\u001b[39m get_trainer(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])(config, model)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshow_progress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[1;32m    154\u001b[0m test_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    155\u001b[0m     test_data, load_best_model\u001b[38;5;241m=\u001b[39msaved, show_progress\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    156\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     training_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 439\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_loss, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_loss\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     training_end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/recbole/trainer/trainer.py:261\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    257\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    258\u001b[0m         losses\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m total_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m total_loss \u001b[38;5;241m+\u001b[39m losses\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_nan(loss)\n\u001b[0;32m--> 261\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msync_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm:\n\u001b[1;32m    263\u001b[0m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm)\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = 'BPR'\n",
    "dataset = 'ml-100k'\n",
    "\n",
    "config_dict = {\n",
    "    # 'normalize_field': None,\n",
    "    'normalize_all': False,\n",
    "    'use_gpu': True,\n",
    "    'gpu_id': 0,\n",
    "\n",
    "    'train_batch_size': 1024,\n",
    "    'eval_batch_size': 1024,\n",
    "\n",
    "    'load_col': {\"inter\": ['user_id', 'item_id', 'timestamp']},\n",
    "    'train_neg_sample_args': None,\n",
    "    # 'train_neg_sample_args': {\n",
    "    #     'distribution': 'uniform',\n",
    "    #     'sample_num': 30,\n",
    "    #     'dynamic': False,\n",
    "    #     'candidate_num': 0,\n",
    "    # },\n",
    "    'eval_args': {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": { \"LS\": \"valid_and_test\" },\n",
    "        \"group_by\": None,\n",
    "        'mode': \"full\"\n",
    "    },\n",
    "    # 'train_neg_sample_args': None\n",
    "}\n",
    "\n",
    "# config = Config(\n",
    "#     model=model,\n",
    "#     dataset=dataset,\n",
    "\n",
    "#     config_dict=config_dict,\n",
    "# )\n",
    "\n",
    "# dataset = create_dataset(config)\n",
    "\n",
    "run_recbole(model=model, dataset=dataset, config_dict=config_dict)\n",
    "\n",
    "# dataset.inter_feat['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macos/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/Users/macos/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(884471835.0, 141)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_suitable_cutoff(ds_name: str) -> tuple:\n",
    "    \"\"\"Get suitable cutoff timestamp: at which there are the most active users\n",
    "\n",
    "    Args:\n",
    "        ds_name (str): dataset name\n",
    "\n",
    "    Returns:\n",
    "        tuple: suitable timestamp and the number of active users\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dataset without normalizing the timestamp\n",
    "    config_dict = {\n",
    "        'normalize_all': False,\n",
    "\n",
    "        'load_col': {\"inter\": ['user_id', 'item_id', 'timestamp']},\n",
    "        'train_neg_sample_args': None,\n",
    "\n",
    "        'eval_args': {\n",
    "            \"order\": \"TO\",\n",
    "            \"split\": { \"LS\": \"valid_and_test\" },\n",
    "            \"group_by\": None,\n",
    "            'mode': 'full'\n",
    "        },\n",
    "    }\n",
    "    config = Config(\n",
    "        model='NPE',\n",
    "        dataset=ds_name,\n",
    "        config_dict=config_dict,\n",
    "    )\n",
    "    init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "    df = create_dataset(config).inter_feat.copy()\n",
    "\n",
    "    # Create dataframe of users and corresponding first/last timestamp\n",
    "    user_max_ts = df.groupby('user_id')['timestamp'].max()\n",
    "    user_min_ts = df.groupby('user_id')['timestamp'].min()\n",
    "    df_user = pd.DataFrame(\n",
    "        {\n",
    "            'max': user_max_ts,\n",
    "            'min': user_min_ts,\n",
    "        },\n",
    "        index=user_max_ts.index\n",
    "    )\n",
    "\n",
    "    counts = defaultdict(int) \n",
    "    for ts in df_user['min']:\n",
    "        counts[ts] += 1\n",
    "    for ts in df_user['max']:\n",
    "        counts[ts] -= 1\n",
    "\n",
    "    timestamps = sorted(counts.keys())\n",
    "    accum = {}\n",
    "\n",
    "    s = 0\n",
    "    for ts in timestamps:\n",
    "        s += counts[ts]\n",
    "        accum[ts] = s\n",
    "    series = pd.Series(accum)\n",
    "\n",
    "    suitable_ts = series.idxmax()\n",
    "    max_active_user = series[suitable_ts]\n",
    "\n",
    "    return suitable_ts, max_active_user\n",
    "\n",
    "get_suitable_cutoff('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1373846400.0, 64126)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_suitable_cutoff('amazon-automotive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
