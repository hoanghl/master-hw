{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hoangle/Uni/Thesis\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from logging import getLogger\n",
    "\n",
    "import yaml\n",
    "from recbole.config import Config\n",
    "from recbole.data import data_preparation, create_dataset\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.utils import (\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    init_seed,\n",
    "    ModelType\n",
    ")\n",
    "\n",
    "import src.utils as utils\n",
    "from src.real_temporal import SimulatedOnlineSequentialDataset, SimulatedOnlineDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Declarations & Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Define flags and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "use_cutoff = False\n",
    "separate_activeness = True\n",
    "\n",
    "model_name = \"NPE\"\n",
    "loss_type = \"CE\"\n",
    "# dataset_name = \"amazon-digital-music\"\n",
    "# cutoff_time = \"1403568000\"\n",
    "\n",
    "dataset_name = \"ml-1m\"\n",
    "cutoff_time = \"991854688\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Define configurations\n",
    "\n",
    "Configuration for data, model, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = utils.Paths(model_name, dataset_name, use_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    # For model \n",
    "    'model': model_name,\n",
    "    'loss_type': loss_type,\n",
    "\n",
    "    # For data\n",
    "    'dataset': dataset_name, \n",
    "    'load_col': {\"inter\": ['user_id', 'item_id', 'timestamp']},\n",
    "    \"separate_activeness\": separate_activeness,\n",
    "    \"cutoff_time\": cutoff_time,\n",
    "    'normalize_all': False,\n",
    "    'user_inter_num_interval': \"[10,inf)\",\n",
    "\n",
    "    # For training\n",
    "    'epochs': 20,\n",
    "    'train_batch_size': 4096,\n",
    "    'eval_step': 1,\n",
    "    'stopping_step': 3,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    # For evaluation\n",
    "    'eval_batch_size': 4096,\n",
    "    'metrics': [\"NDCG\", \"Precision\", \"Recall\", \"MRR\", \"Hit\", \"MAP\"],\n",
    "    'topk': 10,\n",
    "    'valid_metric': 'NDCG@10',\n",
    "\n",
    "    # Environment\n",
    "    'gpu_id': 0,\n",
    "    \"seed\": seed,\n",
    "    \"reproducibility\": True,\n",
    "    'device': 'cuda',\n",
    "    'use_gpu': True,\n",
    "    'data_path': paths.get_path_data_raw(),\n",
    "    \"checkpoint_dir\": paths.get_path_dir_ckpt(),\n",
    "    \"show_progress\": True,\n",
    "    'save_dataset': True,\n",
    "    'dataset_save_path': paths.get_path_data_processed(),\n",
    "    'save_dataloaders': True,\n",
    "    'dataloaders_save_path': paths.get_path_dataloader(),\n",
    "}\n",
    "\n",
    "if use_cutoff is True:\n",
    "    config_dict['eval_args'] = {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"CO\": cutoff_time},\n",
    "        \"group_by\": 'user_id',\n",
    "        'mode': 'full'\n",
    "    }\n",
    "else:\n",
    "    config_dict['eval_args'] = {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": { \"LS\": \"valid_and_test\" },\n",
    "        \"group_by\": None,\n",
    "        'mode': 'full'\n",
    "    }\n",
    "\n",
    "if loss_type == \"CE\":\n",
    "    config_dict[\"train_neg_sample_args\"] = None\n",
    "else:\n",
    "    config_dict[\"train_neg_sample_args\"] = {\n",
    "        \"distribution\": \"uniform\",\n",
    "        \"sample_num\": 1,\n",
    "        # \"dynamic\": False,\n",
    "        # \"candidate_num\": 0,\n",
    "    }\n",
    "\n",
    "config = Config(\n",
    "    model_name,\n",
    "    dataset_name,\n",
    "    config_dict=config_dict,\n",
    "    config_file_list=[paths.get_path_param_conf()],\n",
    ")\n",
    "\n",
    "with open(paths.get_path_conf(), 'w+') as f:\n",
    "    yaml.dump(config.external_config_dict, f, allow_unicode=True)\n",
    "\n",
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "utils.init_logger(config, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Declare necessary components for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangle/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/Users/hoangle/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "29 Jul 21:54    INFO  Saving filtered dataset into [logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts/ml-1m-SequentialDataset.pth]\n",
      "29 Jul 21:54    INFO  Saving split dataloaders into: [logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts/ml-1m-for-NPE-dataloader.pth]\n",
      "29 Jul 21:54    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "29 Jul 21:54    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': None, 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "# Define data related things\n",
    "if use_cutoff is True:\n",
    "    match (config[\"MODEL_TYPE\"]):\n",
    "        case ModelType.GENERAL | ModelType.CONTEXT | ModelType.TRADITIONAL:\n",
    "            ds = \"SimulatedOnlineDataset\"\n",
    "        case ModelType.SEQUENTIAL:\n",
    "            ds = \"SimulatedOnlineSequentialDataset\"\n",
    "        case _:\n",
    "            print(f\"model type: {config['MODEL_TYPE']}\")\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    dataset = eval(ds)(config)\n",
    "else:\n",
    "    dataset = create_dataset(config)\n",
    "\n",
    "if separate_activeness is True:\n",
    "    train_data, valid_data, test_data_active, test_data_inactive = utils.get_loader(dataset, config, True, cutoff_time)\n",
    "else:\n",
    "    train_data, valid_data, test_data = utils.get_loader(dataset, config, False, None)\n",
    "\n",
    "# Define model\n",
    "model_name = config['model']\n",
    "model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "# Define trainer\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Jul 21:54    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 42\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = data/raw/ml-1m\n",
      "checkpoint_dir = logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = data/processed/ml-1m.pth\n",
      "save_dataloaders = True\n",
      "dataloaders_save_path = data/dataloader/NPE-ml-1m.pth\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 3\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': None, 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['NDCG', 'Precision', 'Recall', 'MRR', 'Hit', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = False\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 128\n",
      "loss_type = CE\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "use_cutoff = False\n",
      "device = cpu\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = getLogger()\n",
    "\n",
    "logger.info(config)\n",
    "# logger.info(dataset)\n",
    "# logger.info(model)\n",
    "\n",
    "logger.info(f\"train_dataset         : {len(train_data.dataset)}\")\n",
    "logger.info(f\"valid_dataset         : {len(valid_data.dataset)}\")\n",
    "\n",
    "if separate_activeness is True:\n",
    "    logger.info(f\"test_dataset_active   : {len(test_data_active.dataset)}\")\n",
    "    logger.info(f\"test_dataset_inactive : {len(test_data_inactive.dataset)}\")\n",
    "else:\n",
    "    logger.info(f\"test_dataset          : {len(test_data.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train     0:   0%|                                                           | 0/68 [00:00<?, ?it/s]:   1%|▊                                                  | 1/68 [00:00<00:11,  5.92it/s]:   4%|██▎                                                | 3/68 [00:00<00:07,  9.22it/s]:   7%|███▊                                               | 5/68 [00:00<00:06, 10.34it/s]:  10%|█████▎                                             | 7/68 [00:00<00:05, 10.85it/s]:  13%|██████▊                                            | 9/68 [00:00<00:05, 11.04it/s]:  16%|████████                                          | 11/68 [00:01<00:05, 11.29it/s]:  19%|█████████▌                                        | 13/68 [00:01<00:04, 11.44it/s]:  22%|███████████                                       | 15/68 [00:01<00:05, 10.26it/s]:  25%|████████████▌                                     | 17/68 [00:01<00:05,  9.70it/s]:  28%|█████████████▉                                    | 19/68 [00:01<00:04, 10.12it/s]:  31%|███████████████▍                                  | 21/68 [00:02<00:04,  9.54it/s]:  34%|████████████████▉                                 | 23/68 [00:02<00:04,  9.99it/s]:  37%|██████████████████▍                               | 25/68 [00:02<00:04, 10.42it/s]:  40%|███████████████████▊                              | 27/68 [00:02<00:03, 10.56it/s]:  43%|█████████████████████▎                            | 29/68 [00:02<00:03, 10.67it/s]:  46%|██████████████████████▊                           | 31/68 [00:02<00:03, 10.96it/s]:  49%|████████████████████████▎                         | 33/68 [00:03<00:03, 11.08it/s]:  51%|█████████████████████████▋                        | 35/68 [00:03<00:02, 11.21it/s]:  54%|███████████████████████████▏                      | 37/68 [00:03<00:02, 11.30it/s]:  57%|████████████████████████████▋                     | 39/68 [00:03<00:02, 11.30it/s]:  60%|██████████████████████████████▏                   | 41/68 [00:03<00:02, 11.29it/s]:  63%|███████████████████████████████▌                  | 43/68 [00:04<00:02, 11.48it/s]:  66%|█████████████████████████████████                 | 45/68 [00:04<00:02, 11.47it/s]:  69%|██████████████████████████████████▌               | 47/68 [00:04<00:01, 11.28it/s]:  72%|████████████████████████████████████              | 49/68 [00:04<00:01, 10.26it/s]:  75%|█████████████████████████████████████▌            | 51/68 [00:04<00:01, 10.16it/s]:  78%|██████████████████████████████████████▉           | 53/68 [00:04<00:01, 10.42it/s]:  81%|████████████████████████████████████████▍         | 55/68 [00:05<00:01, 10.75it/s]:  84%|█████████████████████████████████████████▉        | 57/68 [00:05<00:00, 11.04it/s]:  87%|███████████████████████████████████████████▍      | 59/68 [00:05<00:00, 11.25it/s]:  90%|████████████████████████████████████████████▊     | 61/68 [00:05<00:00, 11.41it/s]:  93%|██████████████████████████████████████████████▎   | 63/68 [00:05<00:00, 11.54it/s]:  96%|███████████████████████████████████████████████▊  | 65/68 [00:06<00:00, 11.59it/s]:  99%|█████████████████████████████████████████████████▎| 67/68 [00:06<00:00, 11.68it/s]: 100%|██████████████████████████████████████████████████| 68/68 [00:06<00:00, 10.87it/s]\n",
      "29 Jul 21:54    INFO  epoch 0 training [time: 6.30s, train loss: 525.4435]\n",
      "Evaluate   :   0%|                                                            | 0/1 [00:00<?, ?it/s]: 100%|████████████████████████████████████████████████████| 1/1 [00:00<00:00, 68.05it/s]\n",
      "29 Jul 21:54    INFO  epoch 0 evaluating [time: 0.03s, valid_score: 0.005500]\n",
      "29 Jul 21:54    INFO  valid result: \n",
      "ndcg@10 : 0.0055    precision@10 : 0.0014    recall@10 : 0.0144    mrr@10 : 0.0029    hit@10 : 0.0144    map@10 : 0.0029\n",
      "29 Jul 21:54    INFO  Saving current: logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts/NPE-Jul-29-2024_21-54-47.pth\n",
      "Train     1:   0%|                                                           | 0/68 [00:00<?, ?it/s]:   3%|█▌                                                 | 2/68 [00:00<00:05, 11.33it/s]:   6%|███                                                | 4/68 [00:00<00:05, 11.54it/s]:   9%|████▌                                              | 6/68 [00:00<00:05, 11.57it/s]:  12%|██████                                             | 8/68 [00:00<00:05, 11.74it/s]:  15%|███████▎                                          | 10/68 [00:00<00:05, 10.84it/s]:  18%|████████▊                                         | 12/68 [00:01<00:05, 11.03it/s]:  21%|██████████▎                                       | 14/68 [00:01<00:04, 11.18it/s]:  24%|███████████▊                                      | 16/68 [00:01<00:04, 11.36it/s]:  26%|█████████████▏                                    | 18/68 [00:01<00:04, 11.53it/s]:  29%|██████████████▋                                   | 20/68 [00:01<00:04, 11.65it/s]:  32%|████████████████▏                                 | 22/68 [00:01<00:03, 11.71it/s]:  35%|█████████████████▋                                | 24/68 [00:02<00:03, 11.78it/s]:  38%|███████████████████                               | 26/68 [00:02<00:03, 11.83it/s]:  41%|████████████████████▌                             | 28/68 [00:02<00:03, 11.84it/s]:  44%|██████████████████████                            | 30/68 [00:02<00:03, 11.83it/s]:  47%|███████████████████████▌                          | 32/68 [00:02<00:03, 11.78it/s]:  50%|█████████████████████████                         | 34/68 [00:02<00:02, 11.76it/s]:  53%|██████████████████████████▍                       | 36/68 [00:03<00:02, 11.76it/s]:  56%|███████████████████████████▉                      | 38/68 [00:03<00:02, 11.66it/s]:  59%|█████████████████████████████▍                    | 40/68 [00:03<00:02, 11.53it/s]:  62%|██████████████████████████████▉                   | 42/68 [00:03<00:02, 11.55it/s]:  65%|████████████████████████████████▎                 | 44/68 [00:03<00:02, 11.61it/s]:  68%|█████████████████████████████████▊                | 46/68 [00:03<00:01, 11.64it/s]:  71%|███████████████████████████████████▎              | 48/68 [00:04<00:01, 11.59it/s]:  74%|████████████████████████████████████▊             | 50/68 [00:04<00:01, 11.64it/s]:  76%|██████████████████████████████████████▏           | 52/68 [00:04<00:01, 11.69it/s]:  79%|███████████████████████████████████████▋          | 54/68 [00:04<00:01, 11.73it/s]:  82%|█████████████████████████████████████████▏        | 56/68 [00:04<00:01, 11.74it/s]:  85%|██████████████████████████████████████████▋       | 58/68 [00:04<00:00, 11.78it/s]:  88%|████████████████████████████████████████████      | 60/68 [00:05<00:00, 11.75it/s]:  91%|█████████████████████████████████████████████▌    | 62/68 [00:05<00:00, 11.69it/s]:  94%|███████████████████████████████████████████████   | 64/68 [00:05<00:00, 11.66it/s]:  97%|████████████████████████████████████████████████▌ | 66/68 [00:05<00:00, 11.61it/s]: 100%|██████████████████████████████████████████████████| 68/68 [00:05<00:00, 11.01it/s]: 100%|██████████████████████████████████████████████████| 68/68 [00:05<00:00, 11.55it/s]\n",
      "29 Jul 21:55    INFO  epoch 1 training [time: 5.89s, train loss: 498.9109]\n",
      "Evaluate   :   0%|                                                            | 0/1 [00:00<?, ?it/s]: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 106.23it/s]\n",
      "29 Jul 21:55    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.008100]\n",
      "29 Jul 21:55    INFO  valid result: \n",
      "ndcg@10 : 0.0081    precision@10 : 0.0017    recall@10 : 0.0168    mrr@10 : 0.0056    hit@10 : 0.0168    map@10 : 0.0056\n",
      "29 Jul 21:55    INFO  Saving current: logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts/NPE-Jul-29-2024_21-54-47.pth\n",
      "Train     2:   0%|                                                           | 0/68 [00:00<?, ?it/s]:   3%|█▌                                                 | 2/68 [00:00<00:05, 11.04it/s]:   6%|███                                                | 4/68 [00:00<00:05, 11.38it/s]:   9%|████▌                                              | 6/68 [00:00<00:05, 11.47it/s]:  12%|██████                                             | 8/68 [00:00<00:05, 11.54it/s]:  15%|███████▎                                          | 10/68 [00:00<00:04, 11.61it/s]:  18%|████████▊                                         | 12/68 [00:01<00:04, 11.53it/s]:  21%|██████████▎                                       | 14/68 [00:01<00:04, 11.45it/s]:  24%|███████████▊                                      | 16/68 [00:01<00:04, 11.35it/s]:  26%|█████████████▏                                    | 18/68 [00:01<00:04, 11.40it/s]:  29%|██████████████▋                                   | 20/68 [00:01<00:04, 11.43it/s]:  32%|████████████████▏                                 | 22/68 [00:01<00:04, 11.45it/s]:  35%|█████████████████▋                                | 24/68 [00:02<00:03, 11.52it/s]:  38%|███████████████████                               | 26/68 [00:02<00:03, 10.60it/s]:  41%|████████████████████▌                             | 28/68 [00:02<00:04,  9.90it/s]:  44%|██████████████████████                            | 30/68 [00:02<00:03, 10.04it/s]:  47%|███████████████████████▌                          | 32/68 [00:02<00:03, 10.35it/s]:  50%|█████████████████████████                         | 34/68 [00:03<00:03, 10.58it/s]:  53%|██████████████████████████▍                       | 36/68 [00:03<00:02, 10.78it/s]:  56%|███████████████████████████▉                      | 38/68 [00:03<00:02, 10.88it/s]:  59%|█████████████████████████████▍                    | 40/68 [00:03<00:02, 10.92it/s]:  62%|██████████████████████████████▉                   | 42/68 [00:03<00:02, 11.12it/s]:  65%|████████████████████████████████▎                 | 44/68 [00:03<00:02, 11.28it/s]:  68%|█████████████████████████████████▊                | 46/68 [00:04<00:01, 11.28it/s]:  71%|███████████████████████████████████▎              | 48/68 [00:04<00:01, 11.27it/s]:  74%|████████████████████████████████████▊             | 50/68 [00:04<00:01, 11.31it/s]:  76%|██████████████████████████████████████▏           | 52/68 [00:04<00:01, 11.45it/s]:  79%|███████████████████████████████████████▋          | 54/68 [00:04<00:01, 11.41it/s]:  82%|█████████████████████████████████████████▏        | 56/68 [00:05<00:01, 11.39it/s]:  85%|██████████████████████████████████████████▋       | 58/68 [00:05<00:00, 11.47it/s]:  88%|████████████████████████████████████████████      | 60/68 [00:05<00:00, 11.09it/s]:  91%|█████████████████████████████████████████████▌    | 62/68 [00:05<00:00, 10.94it/s]:  94%|███████████████████████████████████████████████   | 64/68 [00:05<00:00, 11.00it/s]:  97%|████████████████████████████████████████████████▌ | 66/68 [00:05<00:00, 11.03it/s]: 100%|██████████████████████████████████████████████████| 68/68 [00:06<00:00, 10.67it/s]: 100%|██████████████████████████████████████████████████| 68/68 [00:06<00:00, 11.05it/s]\n",
      "29 Jul 21:55    INFO  epoch 2 training [time: 6.16s, train loss: 485.8187]\n",
      "Evaluate   :   0%|                                                            | 0/1 [00:00<?, ?it/s]: 100%|███████████████████████████████████████████████████| 1/1 [00:00<00:00, 121.33it/s]\n",
      "29 Jul 21:55    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 0.008600]\n",
      "29 Jul 21:55    INFO  valid result: \n",
      "ndcg@10 : 0.0086    precision@10 : 0.0022    recall@10 : 0.0217    mrr@10 : 0.0047    hit@10 : 0.0217    map@10 : 0.0047\n",
      "29 Jul 21:55    INFO  Saving current: logs/Jul29_215443_NPE_ml-1m_usecutoff_False/ckpts/NPE-Jul-29-2024_21-54-47.pth\n",
      "Train     3:   0%|                                                           | 0/68 [00:00<?, ?it/s]:   3%|█▌                                                 | 2/68 [00:00<00:05, 11.04it/s]:   6%|███                                                | 4/68 [00:00<00:05, 11.29it/s]:   9%|████▌                                              | 6/68 [00:00<00:05, 11.53it/s]:  12%|██████                                             | 8/68 [00:00<00:05, 11.52it/s]:  15%|███████▎                                          | 10/68 [00:01<00:06,  8.81it/s]:  18%|████████▊                                         | 12/68 [00:01<00:05,  9.34it/s]:  19%|█████████▌                                        | 13/68 [00:01<00:05,  9.45it/s]:  22%|███████████                                       | 15/68 [00:01<00:05, 10.07it/s]:  25%|████████████▌                                     | 17/68 [00:01<00:05,  9.98it/s]:  28%|█████████████▉                                    | 19/68 [00:01<00:05,  9.73it/s]:  31%|███████████████▍                                  | 21/68 [00:02<00:04, 10.12it/s]:  34%|████████████████▉                                 | 23/68 [00:02<00:04, 10.45it/s]:  37%|██████████████████▍                               | 25/68 [00:02<00:04, 10.63it/s]:  40%|███████████████████▊                              | 27/68 [00:02<00:03, 10.65it/s]:  43%|█████████████████████▎                            | 29/68 [00:02<00:03, 10.84it/s]:  46%|██████████████████████▊                           | 31/68 [00:02<00:03, 10.96it/s]:  49%|████████████████████████▎                         | 33/68 [00:03<00:03, 11.05it/s]:  51%|█████████████████████████▋                        | 35/68 [00:03<00:02, 11.01it/s]:  54%|███████████████████████████▏                      | 37/68 [00:03<00:02, 10.97it/s]:  57%|████████████████████████████▋                     | 39/68 [00:03<00:02, 10.94it/s]:  60%|██████████████████████████████▏                   | 41/68 [00:03<00:02, 11.10it/s]:  63%|███████████████████████████████▌                  | 43/68 [00:04<00:02, 11.21it/s]:  66%|█████████████████████████████████                 | 45/68 [00:04<00:02, 11.24it/s]:  69%|██████████████████████████████████▌               | 47/68 [00:04<00:01, 11.26it/s]:  72%|████████████████████████████████████              | 49/68 [00:04<00:01, 11.22it/s]:  75%|█████████████████████████████████████▌            | 51/68 [00:04<00:01, 11.15it/s]:  78%|██████████████████████████████████████▉           | 53/68 [00:04<00:01, 11.19it/s]:  79%|███████████████████████████████████████▋          | 54/68 [00:05<00:01, 10.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshow_progress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m** Validation result\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_valid_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_valid_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     training_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 439\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_loss, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_loss\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     training_end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/trainer.py:261\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    257\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    258\u001b[0m         losses\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m total_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m total_loss \u001b[38;5;241m+\u001b[39m losses\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_nan(loss)\n\u001b[0;32m--> 261\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msync_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm:\n\u001b[1;32m    263\u001b[0m     clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_norm)\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, \n",
    "    valid_data,\n",
    "    verbose=True,\n",
    "    show_progress=config[\"show_progress\"]\n",
    ")\n",
    "\n",
    "logger.info(\"** Validation result\")\n",
    "logger.info(f\"best_valid_score: {best_valid_score:.4f}\")\n",
    "for metric, val in best_valid_result.items():\n",
    "    logger.info(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Jul 03:01    INFO  Loading model structure and parameters from logs/Jul27_004230_ItemKNN_amazon-digital-music_usecutoff_True/ckpts/ItemKNN-Jul-27-2024_02-42-08.pth\n",
      "27 Jul 03:01    INFO  ** Test result\n",
      "27 Jul 03:01    INFO  ndcg@10        : 0.0005\n",
      "27 Jul 03:01    INFO  precision@10   : 0.0001\n",
      "27 Jul 03:01    INFO  recall@10      : 0.0012\n",
      "27 Jul 03:01    INFO  mrr@10         : 0.0003\n",
      "27 Jul 03:01    INFO  hit@10         : 0.0012\n",
      "27 Jul 03:01    INFO  map@10         : 0.0003\n"
     ]
    }
   ],
   "source": [
    "if separate_activeness is True:\n",
    "    pairs = [\n",
    "        (\"Inactive\", test_data_inactive),\n",
    "        (\"Active\", test_data_active),\n",
    "    ]\n",
    "\n",
    "    for tag, test_data in pairs:\n",
    "        test_result = trainer.evaluate(test_data)\n",
    "\n",
    "        logger.info(f\"** Test result: {tag}\")\n",
    "        for metric, val in test_result.items():\n",
    "            logger.info(f\"{metric:<15}: {val:.4f}\")\n",
    "else:\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    logger.info(\"** Test result\")\n",
    "    for metric, val in test_result.items():\n",
    "        logger.info(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tune hyper params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Define hyper params and object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    config = Config(\n",
    "        config_dict=config_dict,\n",
    "        config_file_list=config_file_list,\n",
    "    )\n",
    "\n",
    "    init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "\n",
    "    # Define data related things\n",
    "    # Define data related things\n",
    "    if config[\"use_cutoff\"] is True:\n",
    "        match (config[\"MODEL_TYPE\"]):\n",
    "            case ModelType.GENERAL | ModelType.CONTEXT | ModelType.TRADITIONAL:\n",
    "                ds = \"SimulatedOnlineDataset\"\n",
    "            case ModelType.SEQUENTIAL:\n",
    "                ds = \"SimulatedOnlineSequentialDataset\"\n",
    "            case _:\n",
    "                print(f\"model type: {config['MODEL_TYPE']}\")\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        dataset = eval(ds)(config)\n",
    "    else:\n",
    "        dataset = create_dataset(config)\n",
    "\n",
    "    if separate_activeness is True:\n",
    "        train_data, valid_data, test_data_active, test_data_inactive = utils.get_loader(dataset, config, True, cutoff_time)\n",
    "    else:\n",
    "        train_data, valid_data, test_data = utils.get_loader(dataset, config, False, None)\n",
    "\n",
    "    # Define model\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "    # Define trainer\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "    # Start training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=True)\n",
    "\n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "    }\n",
    "\n",
    "    # Start testing\n",
    "    if separate_activeness is True:\n",
    "        pairs = [\n",
    "            (\"inactive\", test_data_inactive),\n",
    "            (\"active\", test_data_active),\n",
    "        ]\n",
    "\n",
    "        for tag, test_data in pairs:\n",
    "            test_result = trainer.evaluate(test_data)\n",
    "\n",
    "            results[f'test_result_{tag}'] = test_result\n",
    "    else:\n",
    "        test_result = trainer.evaluate(test_data)\n",
    "\n",
    "        results['test_result'] = test_result\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Start tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Jul 03:01    INFO  build_posterior_wrapper took 0.001099 seconds\n",
      "27 Jul 03:01    INFO  TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                  \n",
      "{'k': 200, 'shrink': 0.0}                            \n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Jul 03:01    ERROR  job exception: local variable 'ds' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ds' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      3\u001b[0m max_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      5\u001b[0m hp \u001b[38;5;241m=\u001b[39m HyperTuning(\n\u001b[1;32m      6\u001b[0m     objective_function\u001b[38;5;241m=\u001b[39mobjective_function,\n\u001b[1;32m      7\u001b[0m     algo\u001b[38;5;241m=\u001b[39mtuning_algo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     params_file\u001b[38;5;241m=\u001b[39mpaths\u001b[38;5;241m.\u001b[39mget_path_tuning_conf(),\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/hyper_tuning.py:412\u001b[0m, in \u001b[0;36mHyperTuning.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"begin to search the best parameters\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 412\u001b[0m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_hyper()\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/hyper_tuning.py:347\u001b[0m, in \u001b[0;36mHyperTuning.trial\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_list\u001b[38;5;241m.\u001b[39mappend(params_str)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_dict)\n\u001b[0;32m--> 347\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_config_file_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams2result[params_str] \u001b[38;5;241m=\u001b[39m result_dict\n\u001b[1;32m    349\u001b[0m model, score, bigger \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    350\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    351\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_valid_score\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    352\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_score_bigger\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    353\u001b[0m )\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mobjective_function\u001b[0;34m(config_dict, config_file_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m ModelType\u001b[38;5;241m.\u001b[39mSEQUENTIAL:\n\u001b[1;32m     15\u001b[0m             ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulatedOnlineSequentialDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(\u001b[43mds\u001b[49m)(config)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m create_dataset(config)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ds' referenced before assignment"
     ]
    }
   ],
   "source": [
    "tuning_algo = \"bayes\"\n",
    "early_stop = 3\n",
    "max_evals = 5\n",
    "\n",
    "hp = HyperTuning(\n",
    "    objective_function=objective_function,\n",
    "    algo=tuning_algo,\n",
    "    early_stop=early_stop,\n",
    "    max_evals=max_evals,\n",
    "    fixed_config_file_list=[paths.get_path_conf(), paths.get_path_param_conf()],\n",
    "    params_file=paths.get_path_tuning_conf(),\n",
    ")\n",
    "\n",
    "\n",
    "hp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Export tunning result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  best params: \n",
      "07 Jul 22:36    INFO  {'learning_rate': 0.01}\n",
      "07 Jul 22:36    INFO  best result: \n",
      "07 Jul 22:36    INFO  {'model': 'BPR', 'best_valid_score': 0.0641, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.0641), ('precision@10', 0.0121), ('recall@10', 0.1209), ('mrr@10', 0.0472), ('hit@10', 0.1209), ('map@10', 0.0472)]), 'test_result': OrderedDict([('ndcg@10', 0.0256), ('precision@10', 0.0043), ('recall@10', 0.0429), ('mrr@10', 0.0206), ('hit@10', 0.0429), ('map@10', 0.0206)])}\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "logger.info('best params: ')\n",
    "logger.info(hp.best_params)\n",
    "\n",
    "# print best result\n",
    "logger.info('best result: ')\n",
    "logger.info(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "# export to JSON file\n",
    "tune_result = {\n",
    "    'best_params': hp.best_params,\n",
    "    'best_result': hp.params2result[hp.params2str(hp.best_params)]\n",
    "}\n",
    "with open(paths.get_path_tuning_log(), \"w+\") as f:\n",
    "    json.dump(tune_result, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
