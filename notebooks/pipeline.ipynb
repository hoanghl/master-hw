{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hoangle/Uni/Thesis\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from logging import getLogger\n",
    "\n",
    "import yaml\n",
    "from recbole.config import Config\n",
    "from recbole.data import data_preparation, create_dataset\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.utils import (\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    init_seed,\n",
    "    ModelType\n",
    ")\n",
    "\n",
    "import src.utils as utils\n",
    "from src.real_temporal import SimulatedOnlineSequentialDataset, SimulatedOnlineDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Declarations & Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Define flags and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "use_cutoff = True\n",
    "reproducible = True\n",
    "\n",
    "model_name = \"NeuMF\"\n",
    "loss_type = \"BPR\"\n",
    "# cutoff_time = \"884471835\"\n",
    "dataset_name = \"amazon-digital-music\"\n",
    "cutoff_time = \"1403568000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Define configurations\n",
    "\n",
    "Configuration for data, model, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = utils.Paths(model_name, dataset_name, use_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    # For model \n",
    "    'model': model_name,\n",
    "    'loss_type': loss_type,\n",
    "\n",
    "    # For data\n",
    "    'dataset': dataset_name, \n",
    "    'load_col': {\"inter\": ['user_id', 'item_id', 'timestamp']},\n",
    "    'use_cutoff': use_cutoff,\n",
    "    'normalize_all': False,\n",
    "\n",
    "    # For training\n",
    "    'epochs': 20,\n",
    "    'train_batch_size': 4096,\n",
    "    'eval_step': 1,\n",
    "    'stopping_step': 3,\n",
    "    'learning_rate': 1e-3,\n",
    "    \n",
    "    # For evaluation\n",
    "    'eval_batch_size': 4096,\n",
    "    'metrics': [\"NDCG\", \"Precision\", \"Recall\", \"MRR\", \"Hit\", \"MAP\"],\n",
    "    'topk': 10,\n",
    "    'valid_metric': 'NDCG@10',\n",
    "\n",
    "    # Environment\n",
    "    'gpu_id': 0,\n",
    "    \"seed\": seed,\n",
    "    \"reproducibility\": reproducible,\n",
    "    'device': 'cuda',\n",
    "    'use_gpu': True,\n",
    "    'data_path': paths.get_path_data_raw(),\n",
    "    \"checkpoint_dir\": paths.get_path_dir_ckpt(),\n",
    "    \"show_progress\": True,\n",
    "    'save_dataset': True,\n",
    "    'dataset_save_path': paths.get_path_data_processed(),\n",
    "    'save_dataloaders': True,\n",
    "    'dataloaders_save_path': paths.get_path_dataloader(),\n",
    "}\n",
    "\n",
    "if use_cutoff is True:\n",
    "    config_dict['eval_args'] = {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": {\"CO\": cutoff_time},\n",
    "        \"group_by\": 'user_id',\n",
    "        'mode': 'full'\n",
    "    }\n",
    "else:\n",
    "    config_dict['eval_args'] = {\n",
    "        \"order\": \"TO\",\n",
    "        \"split\": { \"LS\": \"valid_and_test\" },\n",
    "        \"group_by\": None,\n",
    "        'mode': 'full'\n",
    "    }\n",
    "\n",
    "if loss_type == \"CE\":\n",
    "    config_dict[\"train_neg_sample_args\"] = None\n",
    "else:\n",
    "    config_dict[\"train_neg_sample_args\"] = {\n",
    "        \"distribution\": \"uniform\",\n",
    "        \"sample_num\": 1,\n",
    "        # \"dynamic\": False,\n",
    "        # \"candidate_num\": 0,\n",
    "    }\n",
    "\n",
    "config = Config(\n",
    "    model_name,\n",
    "    dataset_name,\n",
    "    config_dict=config_dict,\n",
    "    config_file_list=[paths.get_path_param_conf()],\n",
    ")\n",
    "\n",
    "with open(paths.get_path_conf(), 'w+') as f:\n",
    "    yaml.dump(config.external_config_dict, f, allow_unicode=True)\n",
    "\n",
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "utils.init_logger(config, paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Declare necessary components for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelType.GENERAL: 1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"MODEL_TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Jul 00:14    INFO  Saving split dataloaders into: [logs/Jul27_001427_NeuMF_amazon-digital-music_usecutoff_True/ckpts/amazon-digital-music-for-NeuMF-dataloader.pth]\n",
      "27 Jul 00:15    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "27 Jul 00:15    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '1403568000'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "# Define data related things\n",
    "if use_cutoff is True:\n",
    "    match (config[\"MODEL_TYPE\"]):\n",
    "        case ModelType.GENERAL | ModelType.CONTEXT:\n",
    "            ds = \"SimulatedOnlineDataset\"\n",
    "        case ModelType.SEQUENTIAL:\n",
    "            ds = \"SimulatedOnlineSequentialDataset\"\n",
    "\n",
    "    dataset = eval(ds)(config)\n",
    "else:\n",
    "    dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# Define model\n",
    "model_name = config['model']\n",
    "model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "# Define trainer\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27 Jul 00:15    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 42\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = data/raw/amazon-digital-music\n",
      "checkpoint_dir = logs/Jul27_001427_NeuMF_amazon-digital-music_usecutoff_True/ckpts\n",
      "show_progress"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " = True\n",
      "save_dataset = True\n",
      "dataset_save_path = data/processed/amazon-digital-music.pth\n",
      "save_dataloaders = True\n",
      "dataloaders_save_path = data/dataloader/NeuMF-amazon-digital-music.pth\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 4096\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 3\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'CO': '1403568000'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['NDCG', 'Precision', 'Recall', 'MRR', 'Hit', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = False\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "mf_embedding_size = 64\n",
      "mlp_embedding_size = 64\n",
      "mlp_hidden_size = [128, 64]\n",
      "dropout_prob = 0.1\n",
      "mf_train = True\n",
      "mlp_train = True\n",
      "use_pretrain = False\n",
      "mf_pretrain_path = None\n",
      "mlp_pretrain_path = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "loss_type = BPR\n",
      "use_cutoff = True\n",
      "device = cpu\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = getLogger()\n",
    "\n",
    "logger.info(config)\n",
    "# logger.info(dataset)\n",
    "# logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train     0:   0%|                                                          | 0/170 [00:00<?, ?it/s]:   1%|▎                                                 | 1/170 [00:00<01:05,  2.59it/s]:   1%|▌                                                 | 2/170 [00:00<00:47,  3.53it/s]:   2%|▉                                                 | 3/170 [00:00<00:41,  4.02it/s]:   2%|█▏                                                | 4/170 [00:01<00:38,  4.30it/s]:   3%|█▍                                                | 5/170 [00:01<00:37,  4.45it/s]:   4%|█▊                                                | 6/170 [00:01<00:36,  4.49it/s]:   4%|██                                                | 7/170 [00:01<00:35,  4.56it/s]:   5%|██▎                                               | 8/170 [00:01<00:35,  4.62it/s]:   5%|██▋                                               | 9/170 [00:02<00:34,  4.67it/s]:   6%|██▉                                              | 10/170 [00:02<00:34,  4.67it/s]:   6%|███▏                                             | 11/170 [00:02<00:33,  4.68it/s]:   7%|███▍                                             | 12/170 [00:02<00:33,  4.69it/s]:   8%|███▋                                             | 13/170 [00:02<00:33,  4.73it/s]:   8%|████                                             | 14/170 [00:03<00:32,  4.79it/s]:   9%|████▎                                            | 15/170 [00:03<00:32,  4.77it/s]:   9%|████▌                                            | 16/170 [00:03<00:32,  4.77it/s]:  10%|████▉                                            | 17/170 [00:03<00:32,  4.77it/s]:  11%|█████▏                                           | 18/170 [00:03<00:31,  4.79it/s]:  11%|█████▍                                           | 19/170 [00:04<00:31,  4.78it/s]:  12%|█████▊                                           | 20/170 [00:04<00:31,  4.73it/s]:  12%|██████                                           | 21/170 [00:04<00:31,  4.71it/s]:  13%|██████▎                                          | 22/170 [00:04<00:31,  4.69it/s]:  14%|██████▋                                          | 23/170 [00:05<00:31,  4.68it/s]:  14%|██████▉                                          | 24/170 [00:05<00:31,  4.66it/s]:  15%|███████▏                                         | 25/170 [00:05<00:30,  4.68it/s]:  15%|███████▍                                         | 26/170 [00:05<00:30,  4.69it/s]:  16%|███████▊                                         | 27/170 [00:05<00:30,  4.68it/s]:  16%|████████                                         | 28/170 [00:06<00:30,  4.70it/s]:  17%|████████▎                                        | 29/170 [00:06<00:30,  4.69it/s]:  18%|████████▋                                        | 30/170 [00:06<00:29,  4.69it/s]:  18%|████████▉                                        | 31/170 [00:06<00:29,  4.68it/s]:  19%|█████████▏                                       | 32/170 [00:06<00:29,  4.68it/s]:  19%|█████████▌                                       | 33/170 [00:07<00:29,  4.70it/s]:  20%|█████████▊                                       | 34/170 [00:07<00:28,  4.75it/s]:  21%|██████████                                       | 35/170 [00:07<00:28,  4.80it/s]:  21%|██████████▍                                      | 36/170 [00:07<00:27,  4.81it/s]:  22%|██████████▋                                      | 37/170 [00:07<00:27,  4.87it/s]:  22%|██████████▉                                      | 38/170 [00:08<00:26,  4.91it/s]:  23%|███████████▏                                     | 39/170 [00:08<00:26,  4.93it/s]:  24%|███████████▌                                     | 40/170 [00:08<00:26,  4.94it/s]:  24%|███████████▊                                     | 41/170 [00:08<00:26,  4.93it/s]:  25%|████████████                                     | 42/170 [00:08<00:25,  4.93it/s]:  25%|████████████▍                                    | 43/170 [00:09<00:25,  4.94it/s]:  26%|████████████▋                                    | 44/170 [00:09<00:25,  4.95it/s]:  26%|████████████▉                                    | 45/170 [00:09<00:25,  4.95it/s]:  27%|█████████████▎                                   | 46/170 [00:09<00:25,  4.94it/s]:  28%|█████████████▌                                   | 47/170 [00:09<00:24,  4.95it/s]:  28%|█████████████▊                                   | 48/170 [00:10<00:24,  4.94it/s]:  29%|██████████████                                   | 49/170 [00:10<00:24,  4.94it/s]:  29%|██████████████▍                                  | 50/170 [00:10<00:24,  4.95it/s]:  30%|██████████████▋                                  | 51/170 [00:10<00:24,  4.94it/s]:  31%|██████████████▉                                  | 52/170 [00:11<00:23,  4.94it/s]:  31%|███████████████▎                                 | 53/170 [00:11<00:23,  4.93it/s]:  32%|███████████████▌                                 | 54/170 [00:11<00:23,  4.91it/s]:  32%|███████████████▊                                 | 55/170 [00:11<00:23,  4.90it/s]:  33%|████████████████▏                                | 56/170 [00:11<00:23,  4.92it/s]:  34%|████████████████▍                                | 57/170 [00:12<00:23,  4.73it/s]:  34%|████████████████▋                                | 58/170 [00:12<00:23,  4.77it/s]:  35%|█████████████████                                | 59/170 [00:12<00:23,  4.82it/s]:  35%|█████████████████▎                               | 60/170 [00:12<00:22,  4.88it/s]:  36%|█████████████████▌                               | 61/170 [00:12<00:22,  4.90it/s]:  36%|█████████████████▊                               | 62/170 [00:13<00:21,  4.91it/s]:  37%|██████████████████▏                              | 63/170 [00:13<00:21,  4.91it/s]:  38%|██████████████████▍                              | 64/170 [00:13<00:21,  4.93it/s]:  38%|██████████████████▋                              | 65/170 [00:13<00:21,  4.93it/s]:  39%|███████████████████                              | 66/170 [00:13<00:21,  4.95it/s]:  39%|███████████████████▎                             | 67/170 [00:14<00:20,  4.95it/s]:  40%|███████████████████▌                             | 68/170 [00:14<00:20,  4.95it/s]:  41%|███████████████████▉                             | 69/170 [00:14<00:20,  4.93it/s]:  41%|████████████████████▏                            | 70/170 [00:14<00:20,  4.94it/s]:  42%|████████████████████▍                            | 71/170 [00:14<00:19,  4.96it/s]:  42%|████████████████████▊                            | 72/170 [00:15<00:19,  4.94it/s]:  43%|█████████████████████                            | 73/170 [00:15<00:19,  4.95it/s]:  44%|█████████████████████▎                           | 74/170 [00:15<00:19,  4.92it/s]:  44%|█████████████████████▌                           | 75/170 [00:15<00:19,  4.94it/s]:  45%|█████████████████████▉                           | 76/170 [00:15<00:18,  4.95it/s]:  45%|██████████████████████▏                          | 77/170 [00:16<00:18,  4.93it/s]:  46%|██████████████████████▍                          | 78/170 [00:16<00:18,  4.93it/s]:  46%|██████████████████████▊                          | 79/170 [00:16<00:18,  4.93it/s]:  47%|███████████████████████                          | 80/170 [00:16<00:18,  4.90it/s]:  48%|███████████████████████▎                         | 81/170 [00:16<00:18,  4.92it/s]:  48%|███████████████████████▋                         | 82/170 [00:17<00:17,  4.93it/s]:  49%|███████████████████████▉                         | 83/170 [00:17<00:18,  4.71it/s]:  49%|████████████████████████▏                        | 84/170 [00:17<00:18,  4.76it/s]:  50%|████████████████████████▌                        | 85/170 [00:17<00:17,  4.81it/s]:  51%|████████████████████████▊                        | 86/170 [00:17<00:17,  4.83it/s]:  51%|█████████████████████████                        | 87/170 [00:18<00:17,  4.83it/s]:  52%|█████████████████████████▎                       | 88/170 [00:18<00:16,  4.85it/s]:  52%|█████████████████████████▋                       | 89/170 [00:18<00:16,  4.85it/s]:  53%|█████████████████████████▉                       | 90/170 [00:18<00:16,  4.84it/s]:  54%|██████████████████████████▏                      | 91/170 [00:18<00:16,  4.86it/s]:  54%|██████████████████████████▌                      | 92/170 [00:19<00:15,  4.88it/s]:  55%|██████████████████████████▊                      | 93/170 [00:19<00:15,  4.87it/s]:  55%|███████████████████████████                      | 94/170 [00:19<00:15,  4.88it/s]:  56%|███████████████████████████▍                     | 95/170 [00:19<00:15,  4.85it/s]:  56%|███████████████████████████▋                     | 96/170 [00:20<00:15,  4.88it/s]:  57%|███████████████████████████▉                     | 97/170 [00:20<00:14,  4.89it/s]:  58%|████████████████████████████▏                    | 98/170 [00:20<00:14,  4.86it/s]:  58%|████████████████████████████▌                    | 99/170 [00:20<00:14,  4.86it/s]:  59%|████████████████████████████▏                   | 100/170 [00:20<00:14,  4.85it/s]:  59%|████████████████████████████▌                   | 101/170 [00:21<00:14,  4.86it/s]:  60%|████████████████████████████▊                   | 102/170 [00:21<00:13,  4.88it/s]:  61%|█████████████████████████████                   | 103/170 [00:21<00:13,  4.87it/s]:  61%|█████████████████████████████▎                  | 104/170 [00:21<00:13,  4.87it/s]:  62%|█████████████████████████████▋                  | 105/170 [00:21<00:13,  4.87it/s]:  62%|█████████████████████████████▉                  | 106/170 [00:22<00:13,  4.86it/s]:  63%|██████████████████████████████▏                 | 107/170 [00:22<00:13,  4.58it/s]:  64%|██████████████████████████████▍                 | 108/170 [00:22<00:13,  4.56it/s]:  64%|██████████████████████████████▊                 | 109/170 [00:22<00:13,  4.61it/s]:  65%|███████████████████████████████                 | 110/170 [00:22<00:12,  4.65it/s]:  65%|███████████████████████████████▎                | 111/170 [00:23<00:12,  4.64it/s]:  66%|███████████████████████████████▌                | 112/170 [00:23<00:12,  4.66it/s]:  66%|███████████████████████████████▉                | 113/170 [00:23<00:12,  4.71it/s]:  67%|████████████████████████████████▏               | 114/170 [00:23<00:11,  4.73it/s]:  68%|████████████████████████████████▍               | 115/170 [00:24<00:12,  4.53it/s]:  68%|████████████████████████████████▊               | 116/170 [00:24<00:12,  4.49it/s]:  69%|█████████████████████████████████               | 117/170 [00:24<00:11,  4.56it/s]:  69%|█████████████████████████████████▎              | 118/170 [00:24<00:11,  4.63it/s]:  70%|█████████████████████████████████▌              | 119/170 [00:24<00:10,  4.67it/s]:  71%|█████████████████████████████████▉              | 120/170 [00:25<00:10,  4.72it/s]:  71%|██████████████████████████████████▏             | 121/170 [00:25<00:10,  4.76it/s]:  72%|██████████████████████████████████▍             | 122/170 [00:25<00:10,  4.74it/s]:  72%|██████████████████████████████████▋             | 123/170 [00:25<00:10,  4.46it/s]:  73%|███████████████████████████████████             | 124/170 [00:26<00:10,  4.50it/s]:  74%|███████████████████████████████████▎            | 125/170 [00:26<00:10,  4.49it/s]:  74%|███████████████████████████████████▌            | 126/170 [00:26<00:09,  4.52it/s]:  75%|███████████████████████████████████▊            | 127/170 [00:26<00:09,  4.52it/s]:  75%|████████████████████████████████████▏           | 128/170 [00:26<00:09,  4.53it/s]:  76%|████████████████████████████████████▍           | 129/170 [00:27<00:08,  4.60it/s]:  76%|████████████████████████████████████▋           | 130/170 [00:27<00:08,  4.66it/s]:  77%|████████████████████████████████████▉           | 131/170 [00:27<00:08,  4.68it/s]:  78%|█████████████████████████████████████▎          | 132/170 [00:27<00:08,  4.71it/s]:  78%|█████████████████████████████████████▌          | 133/170 [00:27<00:07,  4.73it/s]:  79%|█████████████████████████████████████▊          | 134/170 [00:28<00:07,  4.74it/s]:  79%|██████████████████████████████████████          | 135/170 [00:28<00:07,  4.70it/s]:  80%|██████████████████████████████████████▍         | 136/170 [00:28<00:07,  4.73it/s]:  81%|██████████████████████████████████████▋         | 137/170 [00:28<00:06,  4.74it/s]:  81%|██████████████████████████████████████▉         | 138/170 [00:28<00:06,  4.77it/s]:  82%|███████████████████████████████████████▏        | 139/170 [00:29<00:06,  4.74it/s]:  82%|███████████████████████████████████████▌        | 140/170 [00:29<00:06,  4.77it/s]:  83%|███████████████████████████████████████▊        | 141/170 [00:29<00:06,  4.58it/s]:  83%|███████████████████████████████████████▊        | 141/170 [00:29<00:06,  4.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_valid_score, best_valid_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshow_progress\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m** Validation result\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_valid_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_valid_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/trainer.py:439\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_data, valid_data, verbose, saved, show_progress, callback_fn)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     training_start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 439\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss_dict[epoch_idx] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_loss, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m train_loss\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m     training_end_time \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/recbole/trainer/trainer.py:238\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, train_data, epoch_idx, loss_func, show_progress)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, interaction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iter_data):\n\u001b[1;32m    237\u001b[0m     interaction \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     sync_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/optim/optimizer.py:825\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 825\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, \n",
    "    valid_data,\n",
    "    verbose=True,\n",
    "    show_progress=config[\"show_progress\"]\n",
    ")\n",
    "\n",
    "logger.info(\"** Validation result\")\n",
    "logger.info(f\"best_valid_score: {best_valid_score:.4f}\")\n",
    "for metric, val in best_valid_result.items():\n",
    "    logger.info(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Start testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:22    INFO  Loading model structure and parameters from logs/Jul07_222207_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-22-09.pth\n",
      "07 Jul 22:22    INFO  ** Test result\n",
      "07 Jul 22:22    INFO  ndcg@10        : 0.0071\n",
      "07 Jul 22:22    INFO  precision@10   : 0.0007\n",
      "07 Jul 22:22    INFO  recall@10      : 0.0071\n",
      "07 Jul 22:22    INFO  mrr@10         : 0.0071\n",
      "07 Jul 22:22    INFO  hit@10         : 0.0071\n",
      "07 Jul 22:22    INFO  map@10         : 0.0071\n"
     ]
    }
   ],
   "source": [
    "test_result = trainer.evaluate(test_data)\n",
    "\n",
    "logger.info(\"** Test result\")\n",
    "for metric, val in test_result.items():\n",
    "    logger.info(f\"{metric:<15}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tune hyper params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Define hyper params and object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    config = Config(\n",
    "        config_dict=config_dict,\n",
    "        config_file_list=config_file_list,\n",
    "    )\n",
    "\n",
    "    init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "\n",
    "    # Define data related things\n",
    "    if use_cutoff is True:\n",
    "        match (config[\"MODEL_TYPE\"]):\n",
    "            case ModelType.GENERAL | ModelType.CONTEXT:\n",
    "                ds = \"SimulatedOnlineDataset\"\n",
    "            case ModelType.SEQUENTIAL:\n",
    "                ds = \"SimulatedOnlineSequentialDataset\"\n",
    "\n",
    "        dataset = eval(ds)(config)\n",
    "    else:\n",
    "        dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Define model\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data._dataset).to(config['device'])\n",
    "\n",
    "    # Define trainer\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "    # Start training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=True)\n",
    "\n",
    "    # Start evaluating\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Start tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  build_posterior_wrapper took 0.000620 seconds\n",
      "07 Jul 22:36    INFO  TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                  \n",
      "{'learning_rate': 0.0005}                            \n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  Saving split dataloaders into: [logs/Jul07_223617_BPR_ml-100k/ckpts/ml-100k-for-BPR-dataloader.pth]\n",
      "07 Jul 22:36    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'alpha': 1.0, 'candidate_num': 0, 'distribution': 'uniform', 'dynamic': False, 'sample_num': 1}]\n",
      "07 Jul 22:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '884471835'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "07 Jul 22:36    INFO  epoch 0 training [time: 0.15s, train loss: 10.3978]\n",
      "07 Jul 22:36    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.000600]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0006    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 1 training [time: 0.15s, train loss: 10.3817]\n",
      "07 Jul 22:36    INFO  epoch 1 evaluating [time: 0.05s, valid_score: 0.001200]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0012    precision@10 : 0.0003    recall@10 : 0.0035    mrr@10 : 0.0005    hit@10 : 0.0035    map@10 : 0.0005\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 2 training [time: 0.19s, train loss: 10.3694]\n",
      "07 Jul 22:36    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  epoch 3 training [time: 0.14s, train loss: 10.3531]\n",
      "07 Jul 22:36    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.001200]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0012    precision@10 : 0.0003    recall@10 : 0.0035    mrr@10 : 0.0005    hit@10 : 0.0035    map@10 : 0.0005\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 4 training [time: 0.14s, train loss: 10.3307]\n",
      "07 Jul 22:36    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.001700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0017    precision@10 : 0.0005    recall@10 : 0.0052    mrr@10 : 0.0007    hit@10 : 0.0052    map@10 : 0.0007\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 5 training [time: 0.14s, train loss: 10.3042]\n",
      "07 Jul 22:36    INFO  epoch 5 evaluating [time: 0.05s, valid_score: 0.003000]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.003    precision@10 : 0.0009    recall@10 : 0.0086    mrr@10 : 0.0013    hit@10 : 0.0086    map@10 : 0.0013\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 6 training [time: 0.14s, train loss: 10.2624]\n",
      "07 Jul 22:36    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.006600]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0066    precision@10 : 0.0017    recall@10 : 0.0173    mrr@10 : 0.0035    hit@10 : 0.0173    map@10 : 0.0035\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  epoch 7 training [time: 0.14s, train loss: 10.2007]\n",
      "07 Jul 22:36    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.010600]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0106    precision@10 : 0.0024    recall@10 : 0.0242    mrr@10 : 0.0065    hit@10 : 0.0242    map@10 : 0.0065\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n",
      "07 Jul 22:36    INFO  Loading model structure and parameters from logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-44.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.0106                     \n",
      "current best valid result:                           \n",
      "OrderedDict([('ndcg@10', 0.0106), ('precision@10', 0.0024), ('recall@10', 0.0242), ('mrr@10', 0.0065), ('hit@10', 0.0242), ('map@10', 0.0065)])\n",
      "current test result:                                 \n",
      "OrderedDict([('ndcg@10', 0.0092), ('precision@10', 0.0014), ('recall@10', 0.0143), ('mrr@10', 0.0079), ('hit@10', 0.0143), ('map@10', 0.0079)])\n",
      " 20%|██        | 1/5 [00:03<00:13,  3.48s/trial, best loss: -0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  build_posterior_wrapper took 0.000422 seconds\n",
      "07 Jul 22:36    INFO  TPE using 1/1 trials with best loss -0.010600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'learning_rate': 0.0001}                                           \n",
      " 20%|██        | 1/5 [00:03<00:13,  3.48s/trial, best loss: -0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  Saving split dataloaders into: [logs/Jul07_223617_BPR_ml-100k/ckpts/ml-100k-for-BPR-dataloader.pth]\n",
      "07 Jul 22:36    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'alpha': 1.0, 'candidate_num': 0, 'distribution': 'uniform', 'dynamic': False, 'sample_num': 1}]\n",
      "07 Jul 22:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '884471835'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "07 Jul 22:36    INFO  epoch 0 training [time: 0.14s, train loss: 10.3983]\n",
      "07 Jul 22:36    INFO  epoch 0 evaluating [time: 0.09s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 1 training [time: 0.15s, train loss: 10.3947]\n",
      "07 Jul 22:36    INFO  epoch 1 evaluating [time: 0.04s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0004    hit@10 : 0.0017    map@10 : 0.0004\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 2 training [time: 0.14s, train loss: 10.3935]\n",
      "07 Jul 22:36    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0004    hit@10 : 0.0017    map@10 : 0.0004\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 3 training [time: 0.15s, train loss: 10.3907]\n",
      "07 Jul 22:36    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 4 training [time: 0.15s, train loss: 10.3870]\n",
      "07 Jul 22:36    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 5 training [time: 0.15s, train loss: 10.3861]\n",
      "07 Jul 22:36    INFO  epoch 5 evaluating [time: 0.09s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 6 training [time: 0.16s, train loss: 10.3837]\n",
      "07 Jul 22:36    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  epoch 7 training [time: 0.15s, train loss: 10.3816]\n",
      "07 Jul 22:36    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n",
      "07 Jul 22:36    INFO  Loading model structure and parameters from logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-47.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.23s/trial, best loss: -0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  build_posterior_wrapper took 0.000349 seconds\n",
      "07 Jul 22:36    INFO  TPE using 2/2 trials with best loss -0.010600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'learning_rate': 0.005}                                            \n",
      " 40%|████      | 2/5 [00:06<00:09,  3.23s/trial, best loss: -0.0106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  Saving split dataloaders into: [logs/Jul07_223617_BPR_ml-100k/ckpts/ml-100k-for-BPR-dataloader.pth]\n",
      "07 Jul 22:36    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'alpha': 1.0, 'candidate_num': 0, 'distribution': 'uniform', 'dynamic': False, 'sample_num': 1}]\n",
      "07 Jul 22:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '884471835'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "07 Jul 22:36    INFO  epoch 0 training [time: 0.14s, train loss: 10.3659]\n",
      "07 Jul 22:36    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.010300]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0103    precision@10 : 0.0019    recall@10 : 0.019    mrr@10 : 0.0077    hit@10 : 0.019    map@10 : 0.0077\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 1 training [time: 0.14s, train loss: 9.5172]\n",
      "07 Jul 22:36    INFO  epoch 1 evaluating [time: 0.05s, valid_score: 0.037900]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0379    precision@10 : 0.0074    recall@10 : 0.0743    mrr@10 : 0.0271    hit@10 : 0.0743    map@10 : 0.0271\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 2 training [time: 0.14s, train loss: 6.6185]\n",
      "07 Jul 22:36    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.047100]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0471    precision@10 : 0.009    recall@10 : 0.0898    mrr@10 : 0.0342    hit@10 : 0.0898    map@10 : 0.0342\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 3 training [time: 0.14s, train loss: 4.5134]\n",
      "07 Jul 22:36    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.053700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0537    precision@10 : 0.0112    recall@10 : 0.1123    mrr@10 : 0.0363    hit@10 : 0.1123    map@10 : 0.0363\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 4 training [time: 0.14s, train loss: 3.7754]\n",
      "07 Jul 22:36    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.052500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0525    precision@10 : 0.0105    recall@10 : 0.1054    mrr@10 : 0.0364    hit@10 : 0.1054    map@10 : 0.0364\n",
      "07 Jul 22:36    INFO  epoch 5 training [time: 0.14s, train loss: 3.4310]\n",
      "07 Jul 22:36    INFO  epoch 5 evaluating [time: 0.10s, valid_score: 0.056500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0565    precision@10 : 0.0105    recall@10 : 0.1054    mrr@10 : 0.0417    hit@10 : 0.1054    map@10 : 0.0417\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 6 training [time: 0.15s, train loss: 2.9613]\n",
      "07 Jul 22:36    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.060500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0605    precision@10 : 0.0117    recall@10 : 0.1174    mrr@10 : 0.0435    hit@10 : 0.1174    map@10 : 0.0435\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  epoch 7 training [time: 0.14s, train loss: 2.7188]\n",
      "07 Jul 22:36    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.060500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0605    precision@10 : 0.0116    recall@10 : 0.1157    mrr@10 : 0.0442    hit@10 : 0.1157    map@10 : 0.0442\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n",
      "07 Jul 22:36    INFO  Loading model structure and parameters from logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-50.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.0605                                    \n",
      "current best valid result:                                          \n",
      "OrderedDict([('ndcg@10', 0.0605), ('precision@10', 0.0116), ('recall@10', 0.1157), ('mrr@10', 0.0442), ('hit@10', 0.1157), ('map@10', 0.0442)])\n",
      "current test result:                                                \n",
      "OrderedDict([('ndcg@10', 0.0226), ('precision@10', 0.0043), ('recall@10', 0.0429), ('mrr@10', 0.0165), ('hit@10', 0.0429), ('map@10', 0.0165)])\n",
      " 60%|██████    | 3/5 [00:09<00:06,  3.13s/trial, best loss: -0.0605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  build_posterior_wrapper took 0.000365 seconds\n",
      "07 Jul 22:36    INFO  TPE using 3/3 trials with best loss -0.060500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'learning_rate': 0.01}                                             \n",
      " 60%|██████    | 3/5 [00:09<00:06,  3.13s/trial, best loss: -0.0605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  Saving split dataloaders into: [logs/Jul07_223617_BPR_ml-100k/ckpts/ml-100k-for-BPR-dataloader.pth]\n",
      "07 Jul 22:36    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'alpha': 1.0, 'candidate_num': 0, 'distribution': 'uniform', 'dynamic': False, 'sample_num': 1}]\n",
      "07 Jul 22:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '884471835'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "07 Jul 22:36    INFO  epoch 0 training [time: 0.14s, train loss: 10.1517]\n",
      "07 Jul 22:36    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.025200]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0252    precision@10 : 0.0052    recall@10 : 0.0518    mrr@10 : 0.0172    hit@10 : 0.0518    map@10 : 0.0172\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  epoch 1 training [time: 0.14s, train loss: 6.4643]\n",
      "07 Jul 22:36    INFO  epoch 1 evaluating [time: 0.05s, valid_score: 0.051900]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0519    precision@10 : 0.0095    recall@10 : 0.095    mrr@10 : 0.0389    hit@10 : 0.095    map@10 : 0.0389\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  epoch 2 training [time: 0.14s, train loss: 3.8800]\n",
      "07 Jul 22:36    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.053200]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0532    precision@10 : 0.01    recall@10 : 0.1002    mrr@10 : 0.039    hit@10 : 0.1002    map@10 : 0.039\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  epoch 3 training [time: 0.14s, train loss: 3.2143]\n",
      "07 Jul 22:36    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.054100]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0541    precision@10 : 0.0102    recall@10 : 0.1019    mrr@10 : 0.0399    hit@10 : 0.1019    map@10 : 0.0399\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  epoch 4 training [time: 0.14s, train loss: 2.5733]\n",
      "07 Jul 22:36    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.050500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0505    precision@10 : 0.0098    recall@10 : 0.0984    mrr@10 : 0.0361    hit@10 : 0.0984    map@10 : 0.0361\n",
      "07 Jul 22:36    INFO  epoch 5 training [time: 0.14s, train loss: 2.3109]\n",
      "07 Jul 22:36    INFO  epoch 5 evaluating [time: 0.05s, valid_score: 0.049200]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0492    precision@10 : 0.0098    recall@10 : 0.0984    mrr@10 : 0.0343    hit@10 : 0.0984    map@10 : 0.0343\n",
      "07 Jul 22:36    INFO  epoch 6 training [time: 0.14s, train loss: 1.9336]\n",
      "07 Jul 22:36    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.061500]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0615    precision@10 : 0.0123    recall@10 : 0.1226    mrr@10 : 0.0433    hit@10 : 0.1226    map@10 : 0.0433\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  epoch 7 training [time: 0.14s, train loss: 1.7443]\n",
      "07 Jul 22:36    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.064100]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0641    precision@10 : 0.0121    recall@10 : 0.1209    mrr@10 : 0.0472    hit@10 : 0.1209    map@10 : 0.0472\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n",
      "07 Jul 22:36    INFO  Loading model structure and parameters from logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-53.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.0641                                    \n",
      "current best valid result:                                          \n",
      "OrderedDict([('ndcg@10', 0.0641), ('precision@10', 0.0121), ('recall@10', 0.1209), ('mrr@10', 0.0472), ('hit@10', 0.1209), ('map@10', 0.0472)])\n",
      "current test result:                                                \n",
      "OrderedDict([('ndcg@10', 0.0256), ('precision@10', 0.0043), ('recall@10', 0.0429), ('mrr@10', 0.0206), ('hit@10', 0.0429), ('map@10', 0.0206)])\n",
      " 80%|████████  | 4/5 [00:12<00:03,  3.07s/trial, best loss: -0.0641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  build_posterior_wrapper took 0.000282 seconds\n",
      "07 Jul 22:36    INFO  TPE using 4/4 trials with best loss -0.064100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'learning_rate': 0.0001}                                           \n",
      " 80%|████████  | 4/5 [00:12<00:03,  3.07s/trial, best loss: -0.0641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  Saving split dataloaders into: [logs/Jul07_223617_BPR_ml-100k/ckpts/ml-100k-for-BPR-dataloader.pth]\n",
      "07 Jul 22:36    INFO  [Training]: train_batch_size = [4096] train_neg_sample_args: [{'alpha': 1.0, 'candidate_num': 0, 'distribution': 'uniform', 'dynamic': False, 'sample_num': 1}]\n",
      "07 Jul 22:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'CO': '884471835'}, 'order': 'TO', 'group_by': 'user_id', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "07 Jul 22:36    INFO  epoch 0 training [time: 0.15s, train loss: 10.3983]\n",
      "07 Jul 22:36    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 1 training [time: 0.15s, train loss: 10.3947]\n",
      "07 Jul 22:36    INFO  epoch 1 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0004    hit@10 : 0.0017    map@10 : 0.0004\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 2 training [time: 0.14s, train loss: 10.3935]\n",
      "07 Jul 22:36    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0004    hit@10 : 0.0017    map@10 : 0.0004\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 3 training [time: 0.14s, train loss: 10.3907]\n",
      "07 Jul 22:36    INFO  epoch 3 evaluating [time: 0.10s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 4 training [time: 0.16s, train loss: 10.3870]\n",
      "07 Jul 22:36    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 5 training [time: 0.15s, train loss: 10.3861]\n",
      "07 Jul 22:36    INFO  epoch 5 evaluating [time: 0.06s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 6 training [time: 0.15s, train loss: 10.3837]\n",
      "07 Jul 22:36    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  epoch 7 training [time: 0.15s, train loss: 10.3816]\n",
      "07 Jul 22:36    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.000700]\n",
      "07 Jul 22:36    INFO  valid result: \n",
      "ndcg@10 : 0.0007    precision@10 : 0.0002    recall@10 : 0.0017    mrr@10 : 0.0003    hit@10 : 0.0017    map@10 : 0.0003\n",
      "07 Jul 22:36    INFO  Saving current: logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n",
      "07 Jul 22:36    INFO  Loading model structure and parameters from logs/Jul07_223617_BPR_ml-100k/ckpts/BPR-Jul-07-2024_22-36-56.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.14s/trial, best loss: -0.0641]\n"
     ]
    }
   ],
   "source": [
    "tuning_algo = \"bayes\"\n",
    "early_stop = 3\n",
    "max_evals = 5\n",
    "\n",
    "hp = HyperTuning(\n",
    "    objective_function=objective_function,\n",
    "    algo=tuning_algo,\n",
    "    early_stop=early_stop,\n",
    "    max_evals=max_evals,\n",
    "    fixed_config_file_list=[paths.get_path_conf(), paths.get_path_param_conf()],\n",
    "    params_file=paths.get_path_tuning_conf(),\n",
    ")\n",
    "\n",
    "\n",
    "hp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Export tunning result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07 Jul 22:36    INFO  best params: \n",
      "07 Jul 22:36    INFO  {'learning_rate': 0.01}\n",
      "07 Jul 22:36    INFO  best result: \n",
      "07 Jul 22:36    INFO  {'model': 'BPR', 'best_valid_score': 0.0641, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.0641), ('precision@10', 0.0121), ('recall@10', 0.1209), ('mrr@10', 0.0472), ('hit@10', 0.1209), ('map@10', 0.0472)]), 'test_result': OrderedDict([('ndcg@10', 0.0256), ('precision@10', 0.0043), ('recall@10', 0.0429), ('mrr@10', 0.0206), ('hit@10', 0.0429), ('map@10', 0.0206)])}\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "logger.info('best params: ')\n",
    "logger.info(hp.best_params)\n",
    "\n",
    "# print best result\n",
    "logger.info('best result: ')\n",
    "logger.info(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "# export to JSON file\n",
    "tune_result = {\n",
    "    'best_params': hp.best_params,\n",
    "    'best_result': hp.params2result[hp.params2str(hp.best_params)]\n",
    "}\n",
    "with open(paths.get_path_tuning_log(), \"w+\") as f:\n",
    "    json.dump(tune_result, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
