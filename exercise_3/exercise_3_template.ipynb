{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dc04a3-1d8c-48e7-b614-15c2c14c0a86",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661219c-4b9d-40e0-b405-58e3edb3c1d1",
   "metadata": {},
   "source": [
    "To install Ax: run `pip install ax-platform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb147c-eb94-425a-804a-896e2371ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "from ax.utils.tutorials.cnn_utils import evaluate, load_mnist, train\n",
    "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
    "from ax.modelbridge.registry import Models\n",
    "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\n",
    "import numpy as np\n",
    "\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0c842-0cd4-45b6-8886-0d0e5d2e07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e330d9b-1a42-429d-a75b-6567482a2660",
   "metadata": {},
   "source": [
    "Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262ba1d-1a8d-4815-adc5-94eaf8a7769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_loader, valid_loader, test_loader = load_mnist(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f90c8-9189-48d2-b0cd-e03042c67576",
   "metadata": {},
   "source": [
    "## (a) Implement CNN\n",
    "\n",
    "See the exercise sheet for specification. Note that you need to figure out the output size of the convolutional layer and max pooling layer to deteremine the size of the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86c9b0-0830-4e3c-9103-dc01eee4e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a110d-7bfd-4611-a565-91ca30e3f4ae",
   "metadata": {},
   "source": [
    "## (b) Bayesian optimization using Ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148af54-c2ed-462e-970d-049f6da6ab5d",
   "metadata": {},
   "source": [
    "Set-up Ax and specify the hyperparameters that will be optimized.\n",
    "\n",
    "See https://ax.dev/tutorials/tune_cnn_service.html for instructions on how to use Ax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840d424-310c-48e4-a302-e798b7ad0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client = AxClient()\n",
    "ax_client.create_experiment(\n",
    "    name=\"tune_cnn_on_mnist\",  # The name of the experiment.\n",
    "    parameters=#TODO\n",
    "    objectives={\"accuracy\": ObjectiveProperties(minimize=False)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e830437-ac8d-4ea2-bbce-771eda4f4581",
   "metadata": {},
   "source": [
    "Wrapper for easy model training and evaluation for given hyperparameters. You need the first during hyperparameter optimization, and the latter is useful for checking whether the chosen settings are actually good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413589c-5884-4d18-bef9-1f4981e82f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(parameterization):\n",
    "\n",
    "    # Extract the kernel size from the ax parameterization\n",
    "    net = CNN(kernel_size=parameterization.get(\"kernel_size\"))\n",
    "    #initializes the network, defines the loss function and optimizer, performs the training loop, and returns the trained model\n",
    "    net = train(\n",
    "        net=net,\n",
    "        train_loader=train_loader,\n",
    "        parameters=parameterization,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # computes the accuracy of the model on the evaluation dataset and returns the metric\n",
    "    return evaluate(\n",
    "        net=net, \n",
    "        data_loader=valid_loader, \n",
    "        dtype=dtype, \n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "def train_test(parameterization):\n",
    "\n",
    "    # Extract the kernel size from the ax parameterization\n",
    "    net = CNN(kernel_size=parameterization.get(\"kernel_size\"))\n",
    "    #initializes the network, defines the loss function and optimizer, performs the training loop, and returns the trained model\n",
    "    net = train(\n",
    "        net=net,\n",
    "        train_loader=train_loader,\n",
    "        parameters=parameterization,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # computes the accuracy of the model on the evaluation dataset and returns the metric\n",
    "    return evaluate(\n",
    "        net=net, \n",
    "        data_loader=test_loader, \n",
    "        dtype=dtype, \n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca7e7bd-6054-4201-843b-285331cefcc4",
   "metadata": {},
   "source": [
    "Run hyperparameter optimization using Bayesian optimization (first 5 iterations uses Sobol random sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedf29b-0a57-4385-aec7-9b263ad0b159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iters = 75\n",
    "for i in range(max_iters):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=train_evaluate(parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8748176d-cd5c-4723-ac33-995cfea2eb82",
   "metadata": {},
   "source": [
    "Plot optimization perfomance (the accuracy of CNN with best hyperparameters found so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4dcadd-4bd8-4868-8bf6-b50ed2be0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "render(\n",
    "    ax_client.get_optimization_trace()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1535406-1e2a-4f62-932e-15b8a960f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out how to get the best parameters and how to check whether they are good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddffb1c-e5da-4739-80e7-72bd8a4d25d9",
   "metadata": {},
   "source": [
    "## (c) grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a1d05-2351-436c-8d42-bee90269694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement here a simple grid search\n",
    "\n",
    "# TODO: Figure out the best parameters and check how well they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea3c8a-fbd2-4fd8-b2dd-ff8c3f16f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple plotting code that plots a similar figure as we got from Ax.\n",
    "bests = []\n",
    "best_so_far = 0.0\n",
    "for key, value in values.items():\n",
    "    if value > best_so_far:\n",
    "        best_so_far = value\n",
    "    bests.append(best_so_far)\n",
    "\n",
    "plt.plot(bests)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ce128-9d89-4f02-a3ea-42614f8b5a3a",
   "metadata": {},
   "source": [
    "# 2. Transfer learning\n",
    "\n",
    "First set up the data and the model. You do not need to change these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5285b-0882-4dd8-9c99-47260be529b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the model architecture\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.MaxPool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Block 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.MaxPool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Block 3\n",
    "        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.MaxPool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(576, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.MaxPool1(self.bn1(self.relu1(self.cnn1(x))))\n",
    "        out = self.MaxPool2(self.bn2(self.relu2(self.cnn2(out))))\n",
    "        out = self.MaxPool3(self.bn3(self.relu3(self.cnn3(out))))\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb26089-8a41-4ca6-8c58-51f7d13bafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility (so that you all have the same data points)\n",
    "# DO NOT CHANGE THIS\n",
    "seed = 2024\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# set the device in use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Download and load Fashion MNIST dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True,\n",
    "                                                  transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True,\n",
    "                                                 transform=transforms.ToTensor())\n",
    "\n",
    "# Select a few samples from the training set\n",
    "train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(train_indices)\n",
    "train_indices = train_indices[:64]\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "\n",
    "# Define dataloaders for training, validation, and testing\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d1c0f-965a-4f2f-ac57-dac5a8856164",
   "metadata": {},
   "source": [
    "## (a) Training the model from scratch\n",
    "\n",
    "Standard training on the tiny labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb0093-64bd-4713-91d3-9b939c54f4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = CNNModel()\n",
    "\n",
    "# Define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# TODO: Choose a suitable optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# Train the model on Fashion MNIST from scratch\n",
    "# TODO: Implement standard optimization routine here\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # Go through data and change parameters, also evaluating the training data metrics\n",
    "    ...\n",
    "\n",
    "        # Example of how to compute the classification accuracy\n",
    "        _, predicted = torch.max(nn.functional.softmax(outputs.data, 1), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).float().sum().item()\n",
    "    \n",
    "    # evaluate test data metrics here\n",
    "    model.eval()\n",
    "    ...\n",
    "    \n",
    " \n",
    "    print(\n",
    "        f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), test_losses, label='test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, epochs+1), train_accs, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accs, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecf9a8-d13b-42f8-8300-4bbc3c935d0b",
   "metadata": {},
   "source": [
    "## (b) and (c): Fine-tuning the model\n",
    "\n",
    "These two parts are combined in the notebook as you re-use so much of the code. Please try to return notebooks that do not copy-paste long chunks of standard optimization code, but rather re-use the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1a53a-6760-4090-88d9-48b1e1ddd97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subtask in ['b','c']:\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = CNNModel()\n",
    "\n",
    "    # Load the pretrained model\n",
    "    model.load_state_dict(torch.load('pretrained_MNIST_model.pt'))\n",
    "\n",
    "    # (b):TODO: Figure out how to freeze the parameters of all layers except the last one\n",
    "\n",
    "    # TODO: Training the model and plotting of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3644340-24a1-4f1a-bc48-ccc65165f069",
   "metadata": {},
   "source": [
    "## (d) Report here the requested final losses and accuracies for the three cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ac95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd24d7d-c217-4884-97a5-4f0a361d1334",
   "metadata": {},
   "source": [
    "# 3 Few-shot learning\n",
    "\n",
    "Set up the data, this time so that we have a specific number of samples from each class. Again no need to change this.\n",
    "\n",
    "The model to be used as the feature extractor is the same as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79d871-6e05-4a76-b241-fc4950a79826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility -- DO NOT CHANGE THIS\n",
    "seed = 2024\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "class KShotCDataset(Dataset):\n",
    "    def __init__(self, fashion_mnist_dataset, k_shot, c_way):\n",
    "        self.fashion_mnist_dataset = fashion_mnist_dataset\n",
    "        self.k_shot = k_shot\n",
    "        self.c_way = c_way\n",
    "\n",
    "        self.data_indices = []\n",
    "\n",
    "        self.class_indices = {label: [] for label in range(self.c_way)}\n",
    "        self.create_balanced_dataset()\n",
    "\n",
    "    def create_balanced_dataset(self):\n",
    "        for idx, (_, label) in enumerate(self.fashion_mnist_dataset):\n",
    "            if label < self.c_way:\n",
    "                self.class_indices[label].append(idx)\n",
    "\n",
    "        for label in range(self.c_way):\n",
    "            self.data_indices.extend(self.class_indices[label][:self.k_shot])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fashion_mnist_index = self.data_indices[index]\n",
    "        image, label = self.fashion_mnist_dataset[fashion_mnist_index]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Load the Fashion MNIST training dataset\n",
    "fashionmnist_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# ...and the test data as well\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True,\n",
    "                                                 transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376685b-1d0e-4fd1-89eb-945e237ca126",
   "metadata": {},
   "source": [
    "## (b) Implement the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b34d4-820c-46dc-84eb-44aeb4be6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes as input the labeled training samples and the test samples\n",
    "# Also need the model that is used for extracting the features\n",
    "# Returns the predicted classes for all test samples (and perhaps already also the classification accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed57330-0410-4e9d-b1b4-e27c0937b5f7",
   "metadata": {},
   "source": [
    "## (c) Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57a96d-270e-4f94-b4ed-0f89ad032a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10  # Number of classes -- ordered labels are selected, e.g. C = 3 means labels=[0, 1, 2]\n",
    "\n",
    "for K in [1, 5]: # Number of shots per class\n",
    "    # Create the K-shot C-way dataset\n",
    "    k_shot_c_dataset = KShotCDataset(fashionmnist_dataset, K, C)\n",
    "    \n",
    "    # Data loader for getting access to the training samples\n",
    "    dataloader = DataLoader(k_shot_c_dataset, batch_size=K*C, shuffle=False)\n",
    "\n",
    "    # Data loader for looping through the test samples\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # TODO: Run your algorithm\n",
    "    \n",
    "    # TODO: Report classification accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
